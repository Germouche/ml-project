{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "I7px9rtuZYKB",
        "NHsLMEXQKaVD",
        "HEe7RJQcKknj",
        "tTsl8fMh-fjF",
        "0W6EIQPmW_LQ",
        "x_yWkIzLa9cO",
        "tfdmKTBdXXhE",
        "UNK0725S5h7l",
        "I7LTLBfFtHYq"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4867cd6384114ca7a945c812fc5c3f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cff8c163102431f8143a46cdf4e5a5e",
              "IPY_MODEL_91244f138e8149468d6785ee58db64b6",
              "IPY_MODEL_81a59201ce9a4046b203485c83a8fdd0"
            ],
            "layout": "IPY_MODEL_746f2db545c944beac6997484ee58867"
          }
        },
        "8cff8c163102431f8143a46cdf4e5a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7a330a0d984909b64acd900710f55f",
            "placeholder": "​",
            "style": "IPY_MODEL_e2a693c52011425d83100a4a6e60d6e1",
            "value": "Downloading: 100%"
          }
        },
        "91244f138e8149468d6785ee58db64b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4994e6adf0f048a3a154d041c0f115fd",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e658dca45db646cda6c478499c8d10df",
            "value": 59
          }
        },
        "81a59201ce9a4046b203485c83a8fdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da55d8ecadf4e7a9eb3eca966bc4c72",
            "placeholder": "​",
            "style": "IPY_MODEL_1f04f01d08664e87ae72c81d0bcc294e",
            "value": " 59.0/59.0 [00:00&lt;00:00, 4.24kB/s]"
          }
        },
        "746f2db545c944beac6997484ee58867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7a330a0d984909b64acd900710f55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a693c52011425d83100a4a6e60d6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4994e6adf0f048a3a154d041c0f115fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e658dca45db646cda6c478499c8d10df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7da55d8ecadf4e7a9eb3eca966bc4c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f04f01d08664e87ae72c81d0bcc294e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0899459fb154d4b9dcb3f991de1bd32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a987b69531c84beeabcf4ecce5e91988",
              "IPY_MODEL_d8a83e40c1284dbb943ae06a5e6385c5",
              "IPY_MODEL_656f77f4164641bc8b06ba17c1f980ab"
            ],
            "layout": "IPY_MODEL_65bb2c829746459cbde8c82532aaedc4"
          }
        },
        "a987b69531c84beeabcf4ecce5e91988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f2a23d80144ae2bdd85adfed6199d4",
            "placeholder": "​",
            "style": "IPY_MODEL_3b911b619c9849798b3a55a03def94d1",
            "value": "Downloading: 100%"
          }
        },
        "d8a83e40c1284dbb943ae06a5e6385c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d96b3b90f9d4169aca1f2583a1710ae",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6917e3c84934c83a2db1e7f4cc6a7c5",
            "value": 433
          }
        },
        "656f77f4164641bc8b06ba17c1f980ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca74c1d2c558475f96a12278dbb1edba",
            "placeholder": "​",
            "style": "IPY_MODEL_07926a440e2b47ffbbcd6ac85afd8977",
            "value": " 433/433 [00:00&lt;00:00, 29.8kB/s]"
          }
        },
        "65bb2c829746459cbde8c82532aaedc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f2a23d80144ae2bdd85adfed6199d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b911b619c9849798b3a55a03def94d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d96b3b90f9d4169aca1f2583a1710ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6917e3c84934c83a2db1e7f4cc6a7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca74c1d2c558475f96a12278dbb1edba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07926a440e2b47ffbbcd6ac85afd8977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdacba8715684ebea3ff65ccbbabb533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b042947694f948aea6bac0345e65bc39",
              "IPY_MODEL_b99862133cd24e63a2c8446ec35679d2",
              "IPY_MODEL_89d78f2e65504c55aa181e6f0a38c9e2"
            ],
            "layout": "IPY_MODEL_2cfbc4bbd322400597cdca75178490ca"
          }
        },
        "b042947694f948aea6bac0345e65bc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85d04fb96d4846ada5536480e38a95af",
            "placeholder": "​",
            "style": "IPY_MODEL_9002f833a126452ab895a358eb4d8afd",
            "value": "Downloading: 100%"
          }
        },
        "b99862133cd24e63a2c8446ec35679d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_646c60f1979c476ca3bfda988d36bdfa",
            "max": 235127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f10d152c7d7241238ae1413e9df78410",
            "value": 235127
          }
        },
        "89d78f2e65504c55aa181e6f0a38c9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2cfe957878f4b749c1cd3263beaaee2",
            "placeholder": "​",
            "style": "IPY_MODEL_e6644728bc3948c7bd5fbc116a9305f8",
            "value": " 235k/235k [00:00&lt;00:00, 185kB/s]"
          }
        },
        "2cfbc4bbd322400597cdca75178490ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d04fb96d4846ada5536480e38a95af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9002f833a126452ab895a358eb4d8afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "646c60f1979c476ca3bfda988d36bdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10d152c7d7241238ae1413e9df78410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2cfe957878f4b749c1cd3263beaaee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6644728bc3948c7bd5fbc116a9305f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb42459883504ea38a3c2ae8e5bfd8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb267ad9980b41128b343340b2903f7b",
              "IPY_MODEL_d2960e635b9341c49752af9e2268dab1",
              "IPY_MODEL_544ea9c002644188948ba38481363921"
            ],
            "layout": "IPY_MODEL_4b6379ac445847d8991f67d8e0238ba8"
          }
        },
        "eb267ad9980b41128b343340b2903f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff9c3060e58f4b948cf8b366127666c7",
            "placeholder": "​",
            "style": "IPY_MODEL_16b3908a967246208c1c3b8905b53298",
            "value": "Downloading: 100%"
          }
        },
        "d2960e635b9341c49752af9e2268dab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_275b7f87a39442b6a2082cc6e7f1dba4",
            "max": 442256004,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8a0c1313e214909b9da4c577dec3753",
            "value": 442256004
          }
        },
        "544ea9c002644188948ba38481363921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297dd471e0964e23bf8be13184e0c787",
            "placeholder": "​",
            "style": "IPY_MODEL_5fbb1dcafe194f3391c9bb3aa2981c34",
            "value": " 442M/442M [00:05&lt;00:00, 83.8MB/s]"
          }
        },
        "4b6379ac445847d8991f67d8e0238ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9c3060e58f4b948cf8b366127666c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b3908a967246208c1c3b8905b53298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "275b7f87a39442b6a2082cc6e7f1dba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a0c1313e214909b9da4c577dec3753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "297dd471e0964e23bf8be13184e0c787": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fbb1dcafe194f3391c9bb3aa2981c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#import every needed Library \n"
      ],
      "metadata": {
        "id": "qfWiL6vlIX7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM2KmqWmMbwy",
        "outputId": "0aa101ef-141a-4f4a-f82e-b7901f45734c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=47ad4382c6cb531f76ed69cf7cfc191a5c950df2ef6e052b1b6bdb9c706c4698\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgY4DzJwINO9",
        "outputId": "7d8ce430-cf3a-4396-da3e-84dd86da6d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n",
        "# from langdetect import detect\n",
        "\n",
        "pd.options.display.max_colwidth = 6000\n",
        "pd.options.display.max_rows = 400\n",
        "np.set_printoptions(suppress=True)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading data"
      ],
      "metadata": {
        "id": "jAmIPsfNIjJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQaR5-z6JeN0",
        "outputId": "5ded1b20-aa1f-4808-ba29-6351a2ea3c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CURR_PATH = !pwd\n",
        "# PARAMETERS\n",
        "PATH_DATA = CURR_PATH[0]\n",
        "PATH_GDRIVE_TMP = \"/content/drive/MyDrive/ML/project2\"  # Google Drive"
      ],
      "metadata": {
        "id": "-fxak0dQUuC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##detect language "
      ],
      "metadata": {
        "id": "KyKD1z4KI2sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect2(x):\n",
        "  try:\n",
        "    return detect(x)\n",
        "  except:\n",
        "    return None"
      ],
      "metadata": {
        "id": "v2ReFTiYI1nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##loading training list"
      ],
      "metadata": {
        "id": "qDjXCkjVn2yX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "with open('/content/drive/MyDrive/ML/project2/listings.pkl', 'rb') as f:\n",
        "    data = pickle.load(f) \n",
        "#combine description\n",
        "data['Listing Description'] = data['Listing Title'] + '.' + data['Listing Description']\n",
        "i = data['Listing Description'].isna()\n",
        "data.loc[i,'Listing Description']= data.loc[i,'Listing Title']"
      ],
      "metadata": {
        "id": "FV_au_NiJBZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#language classify\n",
        "data['Description Langage']=data['Listing Description'].apply(lambda x: detect2(x))\n",
        "print(len(data))\n",
        "#save data with language tag\n",
        "pickle.dump(data, open(PATH_GDRIVE_TMP + \"/data_with_language.pkl\", \"wb\"))\n",
        "data['Description Langage'].value_counts ()"
      ],
      "metadata": {
        "id": "JEKAOi5Sw0FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###for building model"
      ],
      "metadata": {
        "id": "QQmANUpeZSJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only use description length more than 100 characters\n",
        "# data = pickle.load(open(PATH_GDRIVE_TMP+\"/data_with_language.pkl\", \"rb\"))\n",
        "data_de = data.loc[data['Description Langage'] == 'de', (\"Listing Description\",\"Listing Title\",\"Demand\")]\n",
        "data_fr = data.loc[data['Description Langage'] == 'fr', (\"Listing Description\",\"Listing Title\",\"Demand\")]\n",
        "data_it = data.loc[data['Description Langage'] == 'it', (\"Listing Description\",\"Listing Title\",\"Demand\")]\n",
        "print(\"before filter:\",len(data_it))\n",
        "data_it = data_it[data_it[\"Listing Description\"].apply(len)>100]\n",
        "print(len(data_de))\n",
        "print(\"after filter:\",len(data_it))\n",
        "print(len(data_it))\n",
        "print(len(data_de)+len(data_fr)+len(data_it))"
      ],
      "metadata": {
        "id": "hoURRi-OTjSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_de.columns = ['description', 'title', 'demand']\n",
        "data_fr.columns = ['description', 'title', 'demand']\n",
        "data_it.columns = ['description', 'title', 'demand']\n",
        "df_de, val_data_de = train_test_split(data_de, test_size=0.2, random_state=19)\n",
        "df_fr, val_data_fr = train_test_split(data_fr, test_size=0.2, random_state=19)\n",
        "df_it, val_data_it = train_test_split(data_fr, test_size=0.2, random_state=19)\n",
        "print(df_de.head(2))\n",
        "print(df_fr.head(2))\n",
        "print(df_it.head(2))"
      ],
      "metadata": {
        "id": "IEV8LtrKCLu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##loading testing listing"
      ],
      "metadata": {
        "id": "i1T7NXX2nugF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "with open('/content/drive/MyDrive/ML/project2/test_listings_overall.pkl', 'rb') as f:\n",
        "    data = pickle.load(f) \n",
        "data['Listing Description'] = data['Listing Title'] + '.' + data['Listing Description']\n",
        "i = data['Listing Description'].isna()\n",
        "data.loc[i,'Listing Description']= data.loc[i,'Listing Title']"
      ],
      "metadata": {
        "id": "_kK6YCaentjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Description Langage']=data['Listing Description'].apply(lambda x: detect2(x))\n",
        "print(len(data))\n",
        "pickle.dump(data, open(PATH_GDRIVE_TMP + \"/test_data_with_language.pkl\", \"wb\"))\n",
        "data['Description Langage'].value_counts ()"
      ],
      "metadata": {
        "id": "0AL18N6s6Y61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###for testing"
      ],
      "metadata": {
        "id": "I7px9rtuZYKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_de = data.loc[data['Description Langage'] == 'de', (\"Listing Description\",\"Listing Title\",\"Prediction\")]\n",
        "data_fr = data.loc[data['Description Langage'] == 'fr', (\"Listing Description\",\"Listing Title\",\"Prediction\")]\n",
        "data_it = data.loc[data['Description Langage'] == 'it', (\"Listing Description\",\"Listing Title\",\"Prediction\")]\n",
        "print(\"before filter:\",len(data_it))\n",
        "data_it = data_it[data_it[\"Listing Description\"].apply(len)>100]\n",
        "print(len(data_de))\n",
        "print(\"after filter:\",len(data_it))\n",
        "print(len(data_fr))\n",
        "print(len(data_de)+len(data_fr)+len(data_it))"
      ],
      "metadata": {
        "id": "Wp7fjneXoyfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_de.columns = ['description', 'title', 'Prediction']\n",
        "data_fr.columns = ['description', 'title', 'Prediction']\n",
        "data_it.columns = ['description', 'title', 'Prediction']\n",
        "df_de = data_de\n",
        "df_fr = data_fr\n",
        "df_it = data_it\n",
        "print(df_de.head(2))\n",
        "print(df_fr.head(2))\n",
        "print(df_it.head(2))"
      ],
      "metadata": {
        "id": "VEsN6jYdZaEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data processing "
      ],
      "metadata": {
        "id": "TXHe-rkCJveI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##clean1\n",
        "\n",
        "*   Converting text to lower-case\n",
        "*   Standardising representations of a same entity such as “€”, “euro” and “euros” or “m2” and “m²”\n",
        "*   Cleaning out certain patterns that are unlikely to be meaningful such as URLs, phone numbers, emails and bank account references.\n",
        "\n"
      ],
      "metadata": {
        "id": "NHsLMEXQKaVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def treat_euro(text):\n",
        "    text = re.sub(r'(euro[^s])|(euros)|(€)', ' euros', text)\n",
        "    return text\n",
        "def treat_m2(text):\n",
        "    text = re.sub(r'(m2)|(m²)', ' m²', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "b7v6YY56J2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_ibans(text):\n",
        "    pattern = r'fr\\d{2}[ ]\\d{4}[ ]\\d{4}[ ]\\d{4}[ ]\\d{4}[ ]\\d{2}|fr\\d{20}|fr[ ]\\d{2}[ ]\\d{3}[ ]\\d{3}[ ]\\d{3}[ ]\\d{5}'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def remove_space_between_numbers(text):\n",
        "    text = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text)\n",
        "    return text\n",
        "def filter_emails(text):\n",
        "    pattern = r'(?:(?!.*?[.]{2})[a-zA-Z0-9](?:[a-zA-Z0-9.+!%-]{1,64}|)|\\\"[a-zA-Z0-9.+!% -]{1,64}\\\")@[a-zA-Z0-9][a-zA-Z0-9.-]+(.[a-z]{2,}|.[0-9]{1,})'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def filter_ref(text):\n",
        "    pattern = r'(\\(*)(ref|réf)(\\.|[ ])\\d+(\\)*)'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def filter_websites(text):\n",
        "    pattern = r'(http\\:\\/\\/|https\\:\\/\\/)?([a-z0-9][a-z0-9\\-]*\\.)+[a-z][a-z\\-]*'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def filter_phone_numbers(text):\n",
        "    pattern = r'(?:(?:\\+|00)33[\\s.-]{0,3}(?:\\(0\\)[\\s.-]{0,3})?|0)[1-9](?:(?:[\\s.-]?\\d{2}){4}|\\d{2}(?:[\\s.-]?\\d{3}){2})|(\\d{2}[ ]\\d{2}[ ]\\d{3}[ ]\\d{3})'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def filter_tag(text):\n",
        "    pattern = r'<[^>]+>'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "R7DDEjetKXPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace(u'\\xa0', u' ')\n",
        "    text = treat_m2(text)\n",
        "    text = treat_euro(text)\n",
        "    text = filter_phone_numbers(text)\n",
        "    text = filter_emails(text)\n",
        "    text = filter_ibans(text)\n",
        "    text = filter_ref(text)\n",
        "    text = filter_websites(text)\n",
        "    text = remove_space_between_numbers(text)\n",
        "    text = filter_tag(text)\n",
        "    return text\n",
        "df_it['cleaned_description'] = df_it.description.apply(clean_text)"
      ],
      "metadata": {
        "id": "zBvJf5xpKiZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##clean2 \n",
        "only in case of dealing stop word (which is not necessary in this task)"
      ],
      "metadata": {
        "id": "hocMNlkgYcTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###for french"
      ],
      "metadata": {
        "id": "HEe7RJQcKknj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "stemmer = SnowballStemmer(\"french\")\n",
        "stop_words = set(stopwords.words(\"french\"))\n",
        "\n",
        "\n",
        "def clean_text_fr(text, for_embedding=False):\n",
        "    \"\"\"\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean\n",
        "\n",
        "df_fr['cleaned_description'] = df_fr.description.apply(clean_text_fr)"
      ],
      "metadata": {
        "id": "euUn8_QvYM6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dff270-3a41-4e66-8618-14075f7b19fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###for Italian"
      ],
      "metadata": {
        "id": "tTsl8fMh-fjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "stemmer = SnowballStemmer(\"italian\")\n",
        "stop_words = set(stopwords.words(\"italian\"))\n",
        "\n",
        "\n",
        "def clean_text_it(text, for_embedding=False):\n",
        "    \"\"\"\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean\n",
        "\n",
        "df_it['cleaned_description'] = df_it.description.apply(clean_text_it)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVhW1PrS4-nG",
        "outputId": "2299a0fb-27a1-41fc-88b8-7aaca1052bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###for german"
      ],
      "metadata": {
        "id": "0W6EIQPmW_LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "stemmer = SnowballStemmer(\"german\")\n",
        "stop_words = set(stopwords.words(\"german\"))\n",
        "\n",
        "def clean_text_de(text, for_embedding=False):\n",
        "    \"\"\"\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean\n",
        "\n",
        "df_de['cleaned_description'] = df_de.description.apply(clean_text_de)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePf0FD0iXCLF",
        "outputId": "c88c6111-e072-450b-ea33-c97e25e89382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Italian model"
      ],
      "metadata": {
        "id": "Mby9rdOGcJxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization"
      ],
      "metadata": {
        "id": "z7z8BAyRKvU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "EoET8vZjOSZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fff6c75-a866-4856-8c7a-a8e7c089fbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 28.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 102.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 89.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 24.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "J-OGslPmO4ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"dbmdz/bert-base-italian-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4867cd6384114ca7a945c812fc5c3f62",
            "8cff8c163102431f8143a46cdf4e5a5e",
            "91244f138e8149468d6785ee58db64b6",
            "81a59201ce9a4046b203485c83a8fdd0",
            "746f2db545c944beac6997484ee58867",
            "0e7a330a0d984909b64acd900710f55f",
            "e2a693c52011425d83100a4a6e60d6e1",
            "4994e6adf0f048a3a154d041c0f115fd",
            "e658dca45db646cda6c478499c8d10df",
            "7da55d8ecadf4e7a9eb3eca966bc4c72",
            "1f04f01d08664e87ae72c81d0bcc294e",
            "c0899459fb154d4b9dcb3f991de1bd32",
            "a987b69531c84beeabcf4ecce5e91988",
            "d8a83e40c1284dbb943ae06a5e6385c5",
            "656f77f4164641bc8b06ba17c1f980ab",
            "65bb2c829746459cbde8c82532aaedc4",
            "59f2a23d80144ae2bdd85adfed6199d4",
            "3b911b619c9849798b3a55a03def94d1",
            "5d96b3b90f9d4169aca1f2583a1710ae",
            "d6917e3c84934c83a2db1e7f4cc6a7c5",
            "ca74c1d2c558475f96a12278dbb1edba",
            "07926a440e2b47ffbbcd6ac85afd8977",
            "bdacba8715684ebea3ff65ccbbabb533",
            "b042947694f948aea6bac0345e65bc39",
            "b99862133cd24e63a2c8446ec35679d2",
            "89d78f2e65504c55aa181e6f0a38c9e2",
            "2cfbc4bbd322400597cdca75178490ca",
            "85d04fb96d4846ada5536480e38a95af",
            "9002f833a126452ab895a358eb4d8afd",
            "646c60f1979c476ca3bfda988d36bdfa",
            "f10d152c7d7241238ae1413e9df78410",
            "d2cfe957878f4b749c1cd3263beaaee2",
            "e6644728bc3948c7bd5fbc116a9305f8"
          ]
        },
        "id": "wbpSLQ8IPWl8",
        "outputId": "f4138de5-0bb1-4516-cd98-2281556224ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4867cd6384114ca7a945c812fc5c3f62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0899459fb154d4b9dcb3f991de1bd32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/235k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdacba8715684ebea3ff65ccbbabb533"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "encoded_corpus = tokenizer(text=df_it.cleaned_description.tolist(),\n",
        "                            add_special_tokens=True,\n",
        "                            padding='max_length',\n",
        "                            truncation='longest_first',\n",
        "                            max_length=300,\n",
        "                            return_attention_mask=True)\n",
        "input_ids = encoded_corpus['input_ids']\n",
        "attention_mask = encoded_corpus['attention_mask']"
      ],
      "metadata": {
        "id": "IZ-SKp2mKupY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def filter_long_descriptions(tokenizer, descriptions, max_len):\n",
        "    indices = []\n",
        "    lengths = tokenizer(descriptions, padding=False, \n",
        "                     truncation=False, return_length=True)['length']\n",
        "    for i in range(len(descriptions)):\n",
        "        if lengths[i] <= max_len-2:\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "short_descriptions = filter_long_descriptions(tokenizer, \n",
        "                               df_it.cleaned_description.tolist(), 300)\n",
        "input_ids = np.array(input_ids)[short_descriptions]\n",
        "attention_mask = np.array(attention_mask)[short_descriptions]\n",
        "labels = df_it.demand.to_numpy()[short_descriptions]"
      ],
      "metadata": {
        "id": "fDyIimwLK5Sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce35e2c6-214c-42d6-cbb9-ed8a6f07f1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input formatting"
      ],
      "metadata": {
        "id": "ZH9xCgHELBCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###for train"
      ],
      "metadata": {
        "id": "X-tszNYZrMBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_size = 0.1\n",
        "seed = 42\n",
        "train_inputs, test_inputs, train_labels, test_labels = \\\n",
        "            train_test_split(input_ids, labels, test_size=test_size, \n",
        "                             random_state=seed)\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_mask, \n",
        "                                        labels, test_size=test_size, \n",
        "                                        random_state=seed)"
      ],
      "metadata": {
        "id": "vZQ1MFMOLEBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###for testing"
      ],
      "metadata": {
        "id": "IObbtnVirQ35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = input_ids\n",
        "train_masks = attention_mask"
      ],
      "metadata": {
        "id": "VQ_fM2rcrTzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##create_dataloaders"
      ],
      "metadata": {
        "id": "OMlDBFRF5pWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###train dataloader"
      ],
      "metadata": {
        "id": "Lcas6k6Rrd0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "batch_size = 32\n",
        "def create_dataloaders(inputs, masks, labels, batch_size):\n",
        "    input_tensor = torch.tensor(inputs)\n",
        "    mask_tensor = torch.tensor(masks)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_tensor, mask_tensor, \n",
        "                            labels_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
        "                            shuffle=True)\n",
        "    return dataloader\n",
        "train_dataloader = create_dataloaders(train_inputs, train_masks, \n",
        "                                      train_labels, batch_size)\n",
        "test_dataloader = create_dataloaders(test_inputs, test_masks, \n",
        "                                     test_labels, batch_size)"
      ],
      "metadata": {
        "id": "iXeaOiBcLMA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###test dataloader"
      ],
      "metadata": {
        "id": "j1cY8rUJriNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "batch_size = 32\n",
        "def create_dataloaders(inputs, masks, batch_size):\n",
        "    input_tensor = torch.tensor(inputs)\n",
        "    mask_tensor = torch.tensor(masks)\n",
        "    dataset = TensorDataset(input_tensor, mask_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
        "                            shuffle=True)\n",
        "    return dataloader\n",
        "train_dataloader = create_dataloaders(train_inputs, train_masks, batch_size)"
      ],
      "metadata": {
        "id": "WSZkyiucrcek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementing the model in PyTorch"
      ],
      "metadata": {
        "id": "kTLKK7qYLQSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "class AutoRegressor(nn.Module):\n",
        "    \n",
        "    def __init__(self, drop_rate=0.2):\n",
        "        \n",
        "        super(AutoRegressor, self).__init__()\n",
        "        D_in, D_out = 768, 1\n",
        "        self.auto = \\\n",
        "                   AutoModel.from_pretrained(model_name)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(D_in, D_out))\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "        \n",
        "        outputs = self.auto(input_ids, attention_masks)\n",
        "        class_label_output = outputs[1]\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs\n",
        "model = AutoRegressor(drop_rate=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "eb42459883504ea38a3c2ae8e5bfd8f3",
            "eb267ad9980b41128b343340b2903f7b",
            "d2960e635b9341c49752af9e2268dab1",
            "544ea9c002644188948ba38481363921",
            "4b6379ac445847d8991f67d8e0238ba8",
            "ff9c3060e58f4b948cf8b366127666c7",
            "16b3908a967246208c1c3b8905b53298",
            "275b7f87a39442b6a2082cc6e7f1dba4",
            "d8a0c1313e214909b9da4c577dec3753",
            "297dd471e0964e23bf8be13184e0c787",
            "5fbb1dcafe194f3391c9bb3aa2981c34"
          ]
        },
        "id": "j2vWVmIyLXEM",
        "outputId": "2bffac87-bece-41de-84d6-0fb17bc44b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb42459883504ea38a3c2ae8e5bfd8f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setting up the training environment"
      ],
      "metadata": {
        "id": "maXTtsQJLb1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU.\")\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "mYHqHNYrLaCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343b2971-92d7-47a5-9856-568fc494d0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoRegressor(\n",
              "  (auto): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (regressor): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizer, scheduler and loss function"
      ],
      "metadata": {
        "id": "H3x9KepPLjDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=5e-5,\n",
        "                  eps=1e-8)"
      ],
      "metadata": {
        "id": "k31eQSR5Lk8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 20\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,       \n",
        "                 num_warmup_steps=0, num_training_steps=total_steps)"
      ],
      "metadata": {
        "id": "PLdQdVENLoVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.MSELoss()\n",
        "# loss_function = nn.PoissonNLLLoss()"
      ],
      "metadata": {
        "id": "DWNH6_3mLq7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training loop"
      ],
      "metadata": {
        "id": "JWtGr2SLLtLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.clip_grad import clip_grad_norm\n",
        "def train(model, optimizer, scheduler, loss_function, epochs,       \n",
        "          train_dataloader, device, clip_value=2):\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        print(\"-----\")\n",
        "        best_loss = 1e10\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader): \n",
        "            print(step)  \n",
        "            batch_inputs, batch_masks, batch_labels = \\\n",
        "                               tuple(b.to(device) for b in batch)\n",
        "            model.zero_grad()\n",
        "            outputs = model(batch_inputs, batch_masks)           \n",
        "            loss = loss_function(outputs.squeeze().float(), \n",
        "                             batch_labels.squeeze().float())\n",
        "            print(f'step:{step}, loss:{loss}') \n",
        "            loss.backward()\n",
        "            clip_grad_norm(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "                \n",
        "    return model\n",
        "model = train(model, optimizer, scheduler, loss_function, epochs, \n",
        "              train_dataloader, device, clip_value=2)"
      ],
      "metadata": {
        "id": "_xDHKBjKLuWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ee5c3f-7031-4093-e562-7ce329f2161c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "-----\n",
            "0\n",
            "step:0, loss:43.99493408203125\n",
            "1\n",
            "step:1, loss:35.7918701171875\n",
            "2\n",
            "step:2, loss:43.37897491455078\n",
            "3\n",
            "step:3, loss:29.97772789001465\n",
            "4\n",
            "step:4, loss:32.8875732421875\n",
            "5\n",
            "step:5, loss:53.414337158203125\n",
            "6\n",
            "step:6, loss:42.72531509399414\n",
            "7\n",
            "step:7, loss:29.150680541992188\n",
            "8\n",
            "step:8, loss:30.906400680541992\n",
            "9\n",
            "step:9, loss:69.45500946044922\n",
            "10\n",
            "step:10, loss:87.06778717041016\n",
            "11\n",
            "step:11, loss:17.817630767822266\n",
            "12\n",
            "step:12, loss:37.267887115478516\n",
            "13\n",
            "step:13, loss:19.46951675415039\n",
            "14\n",
            "step:14, loss:22.751968383789062\n",
            "15\n",
            "step:15, loss:17.967653274536133\n",
            "16\n",
            "step:16, loss:47.05247497558594\n",
            "17\n",
            "step:17, loss:10.01845932006836\n",
            "18\n",
            "step:18, loss:42.75469207763672\n",
            "19\n",
            "step:19, loss:46.242095947265625\n",
            "20\n",
            "step:20, loss:76.14486694335938\n",
            "21\n",
            "step:21, loss:71.57670593261719\n",
            "22\n",
            "step:22, loss:13.281845092773438\n",
            "23\n",
            "step:23, loss:120.5060806274414\n",
            "24\n",
            "step:24, loss:16.037946701049805\n",
            "25\n",
            "step:25, loss:162.13548278808594\n",
            "26\n",
            "step:26, loss:21.116182327270508\n",
            "27\n",
            "step:27, loss:17.136558532714844\n",
            "28\n",
            "step:28, loss:23.22856903076172\n",
            "29\n",
            "step:29, loss:30.776935577392578\n",
            "30\n",
            "step:30, loss:40.9371452331543\n",
            "31\n",
            "step:31, loss:21.371463775634766\n",
            "32\n",
            "step:32, loss:42.657470703125\n",
            "33\n",
            "step:33, loss:26.48686981201172\n",
            "34\n",
            "step:34, loss:111.82939147949219\n",
            "35\n",
            "step:35, loss:40.05616760253906\n",
            "36\n",
            "step:36, loss:35.71317672729492\n",
            "37\n",
            "step:37, loss:26.23715591430664\n",
            "38\n",
            "step:38, loss:17.62327766418457\n",
            "39\n",
            "step:39, loss:11.122377395629883\n",
            "40\n",
            "step:40, loss:62.58811569213867\n",
            "41\n",
            "step:41, loss:29.769512176513672\n",
            "42\n",
            "step:42, loss:27.29726791381836\n",
            "43\n",
            "step:43, loss:36.093406677246094\n",
            "44\n",
            "step:44, loss:90.68785095214844\n",
            "45\n",
            "step:45, loss:72.73865509033203\n",
            "46\n",
            "step:46, loss:15.555797576904297\n",
            "47\n",
            "step:47, loss:56.63372039794922\n",
            "48\n",
            "step:48, loss:25.224597930908203\n",
            "49\n",
            "step:49, loss:74.2431411743164\n",
            "50\n",
            "step:50, loss:15.192363739013672\n",
            "51\n",
            "step:51, loss:22.963298797607422\n",
            "52\n",
            "step:52, loss:25.266918182373047\n",
            "53\n",
            "step:53, loss:18.270709991455078\n",
            "54\n",
            "step:54, loss:22.05678939819336\n",
            "55\n",
            "step:55, loss:54.980865478515625\n",
            "56\n",
            "step:56, loss:46.49187088012695\n",
            "57\n",
            "step:57, loss:45.49578094482422\n",
            "58\n",
            "step:58, loss:22.24078941345215\n",
            "59\n",
            "step:59, loss:30.02396583557129\n",
            "60\n",
            "step:60, loss:48.40449905395508\n",
            "61\n",
            "step:61, loss:25.015888214111328\n",
            "62\n",
            "step:62, loss:32.285579681396484\n",
            "63\n",
            "step:63, loss:29.199752807617188\n",
            "64\n",
            "step:64, loss:34.317115783691406\n",
            "65\n",
            "step:65, loss:56.10750198364258\n",
            "66\n",
            "step:66, loss:62.27323913574219\n",
            "67\n",
            "step:67, loss:47.371097564697266\n",
            "68\n",
            "step:68, loss:41.20014572143555\n",
            "69\n",
            "step:69, loss:23.19024658203125\n",
            "1\n",
            "-----\n",
            "0\n",
            "step:0, loss:31.18497657775879\n",
            "1\n",
            "step:1, loss:69.15208435058594\n",
            "2\n",
            "step:2, loss:19.27063751220703\n",
            "3\n",
            "step:3, loss:25.41839027404785\n",
            "4\n",
            "step:4, loss:81.30435180664062\n",
            "5\n",
            "step:5, loss:38.770633697509766\n",
            "6\n",
            "step:6, loss:16.134597778320312\n",
            "7\n",
            "step:7, loss:17.88841438293457\n",
            "8\n",
            "step:8, loss:36.11955261230469\n",
            "9\n",
            "step:9, loss:68.18086242675781\n",
            "10\n",
            "step:10, loss:42.815494537353516\n",
            "11\n",
            "step:11, loss:13.120889663696289\n",
            "12\n",
            "step:12, loss:32.95710372924805\n",
            "13\n",
            "step:13, loss:40.74060821533203\n",
            "14\n",
            "step:14, loss:61.48374938964844\n",
            "15\n",
            "step:15, loss:19.874351501464844\n",
            "16\n",
            "step:16, loss:18.57610321044922\n",
            "17\n",
            "step:17, loss:39.53611755371094\n",
            "18\n",
            "step:18, loss:14.031974792480469\n",
            "19\n",
            "step:19, loss:79.2076416015625\n",
            "20\n",
            "step:20, loss:18.534019470214844\n",
            "21\n",
            "step:21, loss:42.62874221801758\n",
            "22\n",
            "step:22, loss:73.18758392333984\n",
            "23\n",
            "step:23, loss:17.27537727355957\n",
            "24\n",
            "step:24, loss:22.03461456298828\n",
            "25\n",
            "step:25, loss:38.171627044677734\n",
            "26\n",
            "step:26, loss:12.916224479675293\n",
            "27\n",
            "step:27, loss:97.13792419433594\n",
            "28\n",
            "step:28, loss:51.26057434082031\n",
            "29\n",
            "step:29, loss:20.652164459228516\n",
            "30\n",
            "step:30, loss:28.439916610717773\n",
            "31\n",
            "step:31, loss:79.58059692382812\n",
            "32\n",
            "step:32, loss:13.81799030303955\n",
            "33\n",
            "step:33, loss:9.37881851196289\n",
            "34\n",
            "step:34, loss:16.394189834594727\n",
            "35\n",
            "step:35, loss:31.4838809967041\n",
            "36\n",
            "step:36, loss:35.21527862548828\n",
            "37\n",
            "step:37, loss:53.5020751953125\n",
            "38\n",
            "step:38, loss:30.76259994506836\n",
            "39\n",
            "step:39, loss:25.77630043029785\n",
            "40\n",
            "step:40, loss:15.191953659057617\n",
            "41\n",
            "step:41, loss:42.16973876953125\n",
            "42\n",
            "step:42, loss:81.56368255615234\n",
            "43\n",
            "step:43, loss:34.03361892700195\n",
            "44\n",
            "step:44, loss:53.948795318603516\n",
            "45\n",
            "step:45, loss:123.18956756591797\n",
            "46\n",
            "step:46, loss:17.78148078918457\n",
            "47\n",
            "step:47, loss:67.29833984375\n",
            "48\n",
            "step:48, loss:22.634387969970703\n",
            "49\n",
            "step:49, loss:82.35308837890625\n",
            "50\n",
            "step:50, loss:33.91864776611328\n",
            "51\n",
            "step:51, loss:13.224811553955078\n",
            "52\n",
            "step:52, loss:13.60856819152832\n",
            "53\n",
            "step:53, loss:56.26118850708008\n",
            "54\n",
            "step:54, loss:56.11487579345703\n",
            "55\n",
            "step:55, loss:31.618566513061523\n",
            "56\n",
            "step:56, loss:13.37211799621582\n",
            "57\n",
            "step:57, loss:16.713088989257812\n",
            "58\n",
            "step:58, loss:54.34711456298828\n",
            "59\n",
            "step:59, loss:41.49808120727539\n",
            "60\n",
            "step:60, loss:20.853687286376953\n",
            "61\n",
            "step:61, loss:53.172264099121094\n",
            "62\n",
            "step:62, loss:24.91766357421875\n",
            "63\n",
            "step:63, loss:21.35262107849121\n",
            "64\n",
            "step:64, loss:17.11362075805664\n",
            "65\n",
            "step:65, loss:26.165678024291992\n",
            "66\n",
            "step:66, loss:26.038883209228516\n",
            "67\n",
            "step:67, loss:40.076393127441406\n",
            "68\n",
            "step:68, loss:15.607454299926758\n",
            "69\n",
            "step:69, loss:24.402799606323242\n",
            "2\n",
            "-----\n",
            "0\n",
            "step:0, loss:37.5655632019043\n",
            "1\n",
            "step:1, loss:24.089563369750977\n",
            "2\n",
            "step:2, loss:36.65106201171875\n",
            "3\n",
            "step:3, loss:38.54973220825195\n",
            "4\n",
            "step:4, loss:87.31287384033203\n",
            "5\n",
            "step:5, loss:48.569725036621094\n",
            "6\n",
            "step:6, loss:57.8791389465332\n",
            "7\n",
            "step:7, loss:51.52574157714844\n",
            "8\n",
            "step:8, loss:15.854278564453125\n",
            "9\n",
            "step:9, loss:20.165740966796875\n",
            "10\n",
            "step:10, loss:22.8547420501709\n",
            "11\n",
            "step:11, loss:87.56655883789062\n",
            "12\n",
            "step:12, loss:26.081954956054688\n",
            "13\n",
            "step:13, loss:15.270997047424316\n",
            "14\n",
            "step:14, loss:27.896324157714844\n",
            "15\n",
            "step:15, loss:10.42104434967041\n",
            "16\n",
            "step:16, loss:32.64692306518555\n",
            "17\n",
            "step:17, loss:32.08867645263672\n",
            "18\n",
            "step:18, loss:48.841331481933594\n",
            "19\n",
            "step:19, loss:24.34821319580078\n",
            "20\n",
            "step:20, loss:60.061100006103516\n",
            "21\n",
            "step:21, loss:27.571155548095703\n",
            "22\n",
            "step:22, loss:21.93886947631836\n",
            "23\n",
            "step:23, loss:57.58528137207031\n",
            "24\n",
            "step:24, loss:16.67254066467285\n",
            "25\n",
            "step:25, loss:19.8017578125\n",
            "26\n",
            "step:26, loss:8.646421432495117\n",
            "27\n",
            "step:27, loss:16.9738712310791\n",
            "28\n",
            "step:28, loss:29.102312088012695\n",
            "29\n",
            "step:29, loss:26.119462966918945\n",
            "30\n",
            "step:30, loss:66.53961181640625\n",
            "31\n",
            "step:31, loss:51.241981506347656\n",
            "32\n",
            "step:32, loss:24.5328369140625\n",
            "33\n",
            "step:33, loss:43.19772720336914\n",
            "34\n",
            "step:34, loss:22.723682403564453\n",
            "35\n",
            "step:35, loss:17.484172821044922\n",
            "36\n",
            "step:36, loss:15.87450122833252\n",
            "37\n",
            "step:37, loss:12.009437561035156\n",
            "38\n",
            "step:38, loss:73.1875228881836\n",
            "39\n",
            "step:39, loss:53.17552947998047\n",
            "40\n",
            "step:40, loss:140.87945556640625\n",
            "41\n",
            "step:41, loss:32.22323989868164\n",
            "42\n",
            "step:42, loss:14.554882049560547\n",
            "43\n",
            "step:43, loss:77.42701721191406\n",
            "44\n",
            "step:44, loss:57.72666549682617\n",
            "45\n",
            "step:45, loss:18.63444709777832\n",
            "46\n",
            "step:46, loss:28.101211547851562\n",
            "47\n",
            "step:47, loss:52.70780563354492\n",
            "48\n",
            "step:48, loss:80.77586364746094\n",
            "49\n",
            "step:49, loss:22.680038452148438\n",
            "50\n",
            "step:50, loss:29.57852554321289\n",
            "51\n",
            "step:51, loss:19.833837509155273\n",
            "52\n",
            "step:52, loss:27.648670196533203\n",
            "53\n",
            "step:53, loss:24.95602035522461\n",
            "54\n",
            "step:54, loss:17.701417922973633\n",
            "55\n",
            "step:55, loss:21.532249450683594\n",
            "56\n",
            "step:56, loss:19.35883331298828\n",
            "57\n",
            "step:57, loss:22.88155174255371\n",
            "58\n",
            "step:58, loss:16.40671157836914\n",
            "59\n",
            "step:59, loss:34.952392578125\n",
            "60\n",
            "step:60, loss:54.933284759521484\n",
            "61\n",
            "step:61, loss:12.93333625793457\n",
            "62\n",
            "step:62, loss:16.14911651611328\n",
            "63\n",
            "step:63, loss:15.666515350341797\n",
            "64\n",
            "step:64, loss:15.459835052490234\n",
            "65\n",
            "step:65, loss:14.180842399597168\n",
            "66\n",
            "step:66, loss:40.25605773925781\n",
            "67\n",
            "step:67, loss:26.805431365966797\n",
            "68\n",
            "step:68, loss:19.761703491210938\n",
            "69\n",
            "step:69, loss:12.274473190307617\n",
            "3\n",
            "-----\n",
            "0\n",
            "step:0, loss:11.538300514221191\n",
            "1\n",
            "step:1, loss:75.90737915039062\n",
            "2\n",
            "step:2, loss:120.82404327392578\n",
            "3\n",
            "step:3, loss:11.235565185546875\n",
            "4\n",
            "step:4, loss:48.73351287841797\n",
            "5\n",
            "step:5, loss:19.273197174072266\n",
            "6\n",
            "step:6, loss:12.858830451965332\n",
            "7\n",
            "step:7, loss:12.97285270690918\n",
            "8\n",
            "step:8, loss:19.550121307373047\n",
            "9\n",
            "step:9, loss:12.13287353515625\n",
            "10\n",
            "step:10, loss:12.751443862915039\n",
            "11\n",
            "step:11, loss:82.21875\n",
            "12\n",
            "step:12, loss:40.23939514160156\n",
            "13\n",
            "step:13, loss:25.480575561523438\n",
            "14\n",
            "step:14, loss:31.09157943725586\n",
            "15\n",
            "step:15, loss:28.51001739501953\n",
            "16\n",
            "step:16, loss:4.365487098693848\n",
            "17\n",
            "step:17, loss:46.76923370361328\n",
            "18\n",
            "step:18, loss:34.165428161621094\n",
            "19\n",
            "step:19, loss:13.619805335998535\n",
            "20\n",
            "step:20, loss:12.94537353515625\n",
            "21\n",
            "step:21, loss:38.942543029785156\n",
            "22\n",
            "step:22, loss:49.84282302856445\n",
            "23\n",
            "step:23, loss:5.9080681800842285\n",
            "24\n",
            "step:24, loss:24.679012298583984\n",
            "25\n",
            "step:25, loss:40.27462387084961\n",
            "26\n",
            "step:26, loss:35.86585998535156\n",
            "27\n",
            "step:27, loss:24.14006996154785\n",
            "28\n",
            "step:28, loss:22.814146041870117\n",
            "29\n",
            "step:29, loss:33.43260955810547\n",
            "30\n",
            "step:30, loss:42.93000411987305\n",
            "31\n",
            "step:31, loss:27.845703125\n",
            "32\n",
            "step:32, loss:25.98584747314453\n",
            "33\n",
            "step:33, loss:30.119834899902344\n",
            "34\n",
            "step:34, loss:17.703338623046875\n",
            "35\n",
            "step:35, loss:27.349563598632812\n",
            "36\n",
            "step:36, loss:29.291154861450195\n",
            "37\n",
            "step:37, loss:12.849143981933594\n",
            "38\n",
            "step:38, loss:23.709436416625977\n",
            "39\n",
            "step:39, loss:37.07160186767578\n",
            "40\n",
            "step:40, loss:18.97345733642578\n",
            "41\n",
            "step:41, loss:33.36688232421875\n",
            "42\n",
            "step:42, loss:17.52495574951172\n",
            "43\n",
            "step:43, loss:70.64241027832031\n",
            "44\n",
            "step:44, loss:23.397171020507812\n",
            "45\n",
            "step:45, loss:29.625089645385742\n",
            "46\n",
            "step:46, loss:27.512710571289062\n",
            "47\n",
            "step:47, loss:15.158817291259766\n",
            "48\n",
            "step:48, loss:17.905696868896484\n",
            "49\n",
            "step:49, loss:10.741253852844238\n",
            "50\n",
            "step:50, loss:23.457294464111328\n",
            "51\n",
            "step:51, loss:24.006500244140625\n",
            "52\n",
            "step:52, loss:56.688446044921875\n",
            "53\n",
            "step:53, loss:47.35099792480469\n",
            "54\n",
            "step:54, loss:40.51844787597656\n",
            "55\n",
            "step:55, loss:109.33431243896484\n",
            "56\n",
            "step:56, loss:29.948123931884766\n",
            "57\n",
            "step:57, loss:26.62348175048828\n",
            "58\n",
            "step:58, loss:27.947507858276367\n",
            "59\n",
            "step:59, loss:28.371692657470703\n",
            "60\n",
            "step:60, loss:19.32918930053711\n",
            "61\n",
            "step:61, loss:40.121395111083984\n",
            "62\n",
            "step:62, loss:13.978032112121582\n",
            "63\n",
            "step:63, loss:24.649383544921875\n",
            "64\n",
            "step:64, loss:12.168124198913574\n",
            "65\n",
            "step:65, loss:15.723760604858398\n",
            "66\n",
            "step:66, loss:15.02527904510498\n",
            "67\n",
            "step:67, loss:18.602157592773438\n",
            "68\n",
            "step:68, loss:96.28948211669922\n",
            "69\n",
            "step:69, loss:188.46360778808594\n",
            "4\n",
            "-----\n",
            "0\n",
            "step:0, loss:46.96477508544922\n",
            "1\n",
            "step:1, loss:60.807857513427734\n",
            "2\n",
            "step:2, loss:23.186725616455078\n",
            "3\n",
            "step:3, loss:66.34576416015625\n",
            "4\n",
            "step:4, loss:22.863555908203125\n",
            "5\n",
            "step:5, loss:15.551653861999512\n",
            "6\n",
            "step:6, loss:13.378647804260254\n",
            "7\n",
            "step:7, loss:19.698970794677734\n",
            "8\n",
            "step:8, loss:23.589839935302734\n",
            "9\n",
            "step:9, loss:30.17626190185547\n",
            "10\n",
            "step:10, loss:92.23379516601562\n",
            "11\n",
            "step:11, loss:101.97633361816406\n",
            "12\n",
            "step:12, loss:35.14691925048828\n",
            "13\n",
            "step:13, loss:15.125776290893555\n",
            "14\n",
            "step:14, loss:16.767427444458008\n",
            "15\n",
            "step:15, loss:10.880838394165039\n",
            "16\n",
            "step:16, loss:15.659971237182617\n",
            "17\n",
            "step:17, loss:15.052672386169434\n",
            "18\n",
            "step:18, loss:6.86737585067749\n",
            "19\n",
            "step:19, loss:21.748394012451172\n",
            "20\n",
            "step:20, loss:6.881333827972412\n",
            "21\n",
            "step:21, loss:56.0012321472168\n",
            "22\n",
            "step:22, loss:14.829607009887695\n",
            "23\n",
            "step:23, loss:6.443345069885254\n",
            "24\n",
            "step:24, loss:11.012295722961426\n",
            "25\n",
            "step:25, loss:9.626834869384766\n",
            "26\n",
            "step:26, loss:10.9824857711792\n",
            "27\n",
            "step:27, loss:7.50156307220459\n",
            "28\n",
            "step:28, loss:16.304428100585938\n",
            "29\n",
            "step:29, loss:24.60719108581543\n",
            "30\n",
            "step:30, loss:6.357156753540039\n",
            "31\n",
            "step:31, loss:37.70697021484375\n",
            "32\n",
            "step:32, loss:32.29506301879883\n",
            "33\n",
            "step:33, loss:8.661590576171875\n",
            "34\n",
            "step:34, loss:39.367366790771484\n",
            "35\n",
            "step:35, loss:37.685279846191406\n",
            "36\n",
            "step:36, loss:28.524572372436523\n",
            "37\n",
            "step:37, loss:29.169639587402344\n",
            "38\n",
            "step:38, loss:53.72608947753906\n",
            "39\n",
            "step:39, loss:22.257457733154297\n",
            "40\n",
            "step:40, loss:16.149890899658203\n",
            "41\n",
            "step:41, loss:19.57867431640625\n",
            "42\n",
            "step:42, loss:19.032270431518555\n",
            "43\n",
            "step:43, loss:27.3682918548584\n",
            "44\n",
            "step:44, loss:36.77790832519531\n",
            "45\n",
            "step:45, loss:8.778898239135742\n",
            "46\n",
            "step:46, loss:68.32797241210938\n",
            "47\n",
            "step:47, loss:75.71533966064453\n",
            "48\n",
            "step:48, loss:27.351882934570312\n",
            "49\n",
            "step:49, loss:45.84524154663086\n",
            "50\n",
            "step:50, loss:22.542137145996094\n",
            "51\n",
            "step:51, loss:11.168256759643555\n",
            "52\n",
            "step:52, loss:18.82461166381836\n",
            "53\n",
            "step:53, loss:57.205589294433594\n",
            "54\n",
            "step:54, loss:35.489341735839844\n",
            "55\n",
            "step:55, loss:25.234617233276367\n",
            "56\n",
            "step:56, loss:32.586082458496094\n",
            "57\n",
            "step:57, loss:15.224967956542969\n",
            "58\n",
            "step:58, loss:69.95030212402344\n",
            "59\n",
            "step:59, loss:21.718616485595703\n",
            "60\n",
            "step:60, loss:18.19685173034668\n",
            "61\n",
            "step:61, loss:14.423360824584961\n",
            "62\n",
            "step:62, loss:27.04404640197754\n",
            "63\n",
            "step:63, loss:14.719409942626953\n",
            "64\n",
            "step:64, loss:18.48814582824707\n",
            "65\n",
            "step:65, loss:44.51994323730469\n",
            "66\n",
            "step:66, loss:15.546860694885254\n",
            "67\n",
            "step:67, loss:28.0838680267334\n",
            "68\n",
            "step:68, loss:25.29357147216797\n",
            "69\n",
            "step:69, loss:3.690751552581787\n",
            "5\n",
            "-----\n",
            "0\n",
            "step:0, loss:17.70626449584961\n",
            "1\n",
            "step:1, loss:17.223621368408203\n",
            "2\n",
            "step:2, loss:50.887210845947266\n",
            "3\n",
            "step:3, loss:19.09264373779297\n",
            "4\n",
            "step:4, loss:63.550750732421875\n",
            "5\n",
            "step:5, loss:23.95995330810547\n",
            "6\n",
            "step:6, loss:13.436318397521973\n",
            "7\n",
            "step:7, loss:13.09986686706543\n",
            "8\n",
            "step:8, loss:36.356414794921875\n",
            "9\n",
            "step:9, loss:21.53131103515625\n",
            "10\n",
            "step:10, loss:15.851046562194824\n",
            "11\n",
            "step:11, loss:89.2239761352539\n",
            "12\n",
            "step:12, loss:13.958887100219727\n",
            "13\n",
            "step:13, loss:8.450925827026367\n",
            "14\n",
            "step:14, loss:9.755514144897461\n",
            "15\n",
            "step:15, loss:16.772953033447266\n",
            "16\n",
            "step:16, loss:8.99333667755127\n",
            "17\n",
            "step:17, loss:19.400774002075195\n",
            "18\n",
            "step:18, loss:35.14046859741211\n",
            "19\n",
            "step:19, loss:9.03116226196289\n",
            "20\n",
            "step:20, loss:86.89163208007812\n",
            "21\n",
            "step:21, loss:16.866558074951172\n",
            "22\n",
            "step:22, loss:20.694110870361328\n",
            "23\n",
            "step:23, loss:12.157686233520508\n",
            "24\n",
            "step:24, loss:29.067277908325195\n",
            "25\n",
            "step:25, loss:39.636474609375\n",
            "26\n",
            "step:26, loss:9.92276668548584\n",
            "27\n",
            "step:27, loss:117.12200164794922\n",
            "28\n",
            "step:28, loss:18.739898681640625\n",
            "29\n",
            "step:29, loss:37.245643615722656\n",
            "30\n",
            "step:30, loss:21.745075225830078\n",
            "31\n",
            "step:31, loss:26.553707122802734\n",
            "32\n",
            "step:32, loss:26.517284393310547\n",
            "33\n",
            "step:33, loss:40.64863204956055\n",
            "34\n",
            "step:34, loss:14.446736335754395\n",
            "35\n",
            "step:35, loss:22.534379959106445\n",
            "36\n",
            "step:36, loss:23.805484771728516\n",
            "37\n",
            "step:37, loss:6.202761650085449\n",
            "38\n",
            "step:38, loss:56.390830993652344\n",
            "39\n",
            "step:39, loss:9.388958930969238\n",
            "40\n",
            "step:40, loss:22.914222717285156\n",
            "41\n",
            "step:41, loss:11.690024375915527\n",
            "42\n",
            "step:42, loss:12.999286651611328\n",
            "43\n",
            "step:43, loss:9.854696273803711\n",
            "44\n",
            "step:44, loss:38.28948974609375\n",
            "45\n",
            "step:45, loss:23.154579162597656\n",
            "46\n",
            "step:46, loss:27.067562103271484\n",
            "47\n",
            "step:47, loss:26.17169189453125\n",
            "48\n",
            "step:48, loss:92.51607513427734\n",
            "49\n",
            "step:49, loss:34.16375732421875\n",
            "50\n",
            "step:50, loss:11.041653633117676\n",
            "51\n",
            "step:51, loss:5.538533687591553\n",
            "52\n",
            "step:52, loss:16.122467041015625\n",
            "53\n",
            "step:53, loss:7.415714263916016\n",
            "54\n",
            "step:54, loss:14.934123992919922\n",
            "55\n",
            "step:55, loss:39.188560485839844\n",
            "56\n",
            "step:56, loss:53.75730895996094\n",
            "57\n",
            "step:57, loss:35.353580474853516\n",
            "58\n",
            "step:58, loss:18.233322143554688\n",
            "59\n",
            "step:59, loss:14.667433738708496\n",
            "60\n",
            "step:60, loss:13.733230590820312\n",
            "61\n",
            "step:61, loss:24.953460693359375\n",
            "62\n",
            "step:62, loss:58.67464828491211\n",
            "63\n",
            "step:63, loss:12.91388988494873\n",
            "64\n",
            "step:64, loss:16.932008743286133\n",
            "65\n",
            "step:65, loss:39.80097198486328\n",
            "66\n",
            "step:66, loss:21.443700790405273\n",
            "67\n",
            "step:67, loss:13.912015914916992\n",
            "68\n",
            "step:68, loss:7.640524864196777\n",
            "69\n",
            "step:69, loss:13.2388334274292\n",
            "6\n",
            "-----\n",
            "0\n",
            "step:0, loss:50.308982849121094\n",
            "1\n",
            "step:1, loss:41.839088439941406\n",
            "2\n",
            "step:2, loss:33.744712829589844\n",
            "3\n",
            "step:3, loss:11.247673034667969\n",
            "4\n",
            "step:4, loss:11.405434608459473\n",
            "5\n",
            "step:5, loss:41.86767578125\n",
            "6\n",
            "step:6, loss:18.85677146911621\n",
            "7\n",
            "step:7, loss:25.154926300048828\n",
            "8\n",
            "step:8, loss:7.661681652069092\n",
            "9\n",
            "step:9, loss:9.163837432861328\n",
            "10\n",
            "step:10, loss:15.99181079864502\n",
            "11\n",
            "step:11, loss:35.004573822021484\n",
            "12\n",
            "step:12, loss:32.60050964355469\n",
            "13\n",
            "step:13, loss:12.240144729614258\n",
            "14\n",
            "step:14, loss:34.7459716796875\n",
            "15\n",
            "step:15, loss:53.61610412597656\n",
            "16\n",
            "step:16, loss:18.164955139160156\n",
            "17\n",
            "step:17, loss:17.568645477294922\n",
            "18\n",
            "step:18, loss:42.29231262207031\n",
            "19\n",
            "step:19, loss:31.19675064086914\n",
            "20\n",
            "step:20, loss:25.11726951599121\n",
            "21\n",
            "step:21, loss:20.4355411529541\n",
            "22\n",
            "step:22, loss:15.449766159057617\n",
            "23\n",
            "step:23, loss:9.52370548248291\n",
            "24\n",
            "step:24, loss:13.307744026184082\n",
            "25\n",
            "step:25, loss:14.123834609985352\n",
            "26\n",
            "step:26, loss:19.893686294555664\n",
            "27\n",
            "step:27, loss:25.710166931152344\n",
            "28\n",
            "step:28, loss:22.118732452392578\n",
            "29\n",
            "step:29, loss:30.02044105529785\n",
            "30\n",
            "step:30, loss:16.259830474853516\n",
            "31\n",
            "step:31, loss:19.43572235107422\n",
            "32\n",
            "step:32, loss:11.91805648803711\n",
            "33\n",
            "step:33, loss:92.31771087646484\n",
            "34\n",
            "step:34, loss:7.585724830627441\n",
            "35\n",
            "step:35, loss:8.946989059448242\n",
            "36\n",
            "step:36, loss:11.50904655456543\n",
            "37\n",
            "step:37, loss:20.6766414642334\n",
            "38\n",
            "step:38, loss:29.867231369018555\n",
            "39\n",
            "step:39, loss:8.662333488464355\n",
            "40\n",
            "step:40, loss:13.760889053344727\n",
            "41\n",
            "step:41, loss:6.736142158508301\n",
            "42\n",
            "step:42, loss:91.40931701660156\n",
            "43\n",
            "step:43, loss:11.52067756652832\n",
            "44\n",
            "step:44, loss:50.70074462890625\n",
            "45\n",
            "step:45, loss:20.47126007080078\n",
            "46\n",
            "step:46, loss:14.193841934204102\n",
            "47\n",
            "step:47, loss:16.04058837890625\n",
            "48\n",
            "step:48, loss:8.348584175109863\n",
            "49\n",
            "step:49, loss:21.060245513916016\n",
            "50\n",
            "step:50, loss:9.134997367858887\n",
            "51\n",
            "step:51, loss:35.732330322265625\n",
            "52\n",
            "step:52, loss:37.483665466308594\n",
            "53\n",
            "step:53, loss:64.22280883789062\n",
            "54\n",
            "step:54, loss:27.29806900024414\n",
            "55\n",
            "step:55, loss:16.245452880859375\n",
            "56\n",
            "step:56, loss:17.095340728759766\n",
            "57\n",
            "step:57, loss:12.945772171020508\n",
            "58\n",
            "step:58, loss:13.54078483581543\n",
            "59\n",
            "step:59, loss:15.721661567687988\n",
            "60\n",
            "step:60, loss:13.17798137664795\n",
            "61\n",
            "step:61, loss:50.74613571166992\n",
            "62\n",
            "step:62, loss:22.26901626586914\n",
            "63\n",
            "step:63, loss:55.92317199707031\n",
            "64\n",
            "step:64, loss:12.056235313415527\n",
            "65\n",
            "step:65, loss:30.049278259277344\n",
            "66\n",
            "step:66, loss:25.717103958129883\n",
            "67\n",
            "step:67, loss:29.041370391845703\n",
            "68\n",
            "step:68, loss:15.815020561218262\n",
            "69\n",
            "step:69, loss:3.7209203243255615\n",
            "7\n",
            "-----\n",
            "0\n",
            "step:0, loss:11.793606758117676\n",
            "1\n",
            "step:1, loss:88.95527648925781\n",
            "2\n",
            "step:2, loss:14.16556167602539\n",
            "3\n",
            "step:3, loss:8.141517639160156\n",
            "4\n",
            "step:4, loss:23.667835235595703\n",
            "5\n",
            "step:5, loss:11.470246315002441\n",
            "6\n",
            "step:6, loss:16.73421287536621\n",
            "7\n",
            "step:7, loss:12.566301345825195\n",
            "8\n",
            "step:8, loss:18.816707611083984\n",
            "9\n",
            "step:9, loss:5.3662824630737305\n",
            "10\n",
            "step:10, loss:13.142541885375977\n",
            "11\n",
            "step:11, loss:11.213619232177734\n",
            "12\n",
            "step:12, loss:28.362287521362305\n",
            "13\n",
            "step:13, loss:45.94300842285156\n",
            "14\n",
            "step:14, loss:65.8322982788086\n",
            "15\n",
            "step:15, loss:6.419656753540039\n",
            "16\n",
            "step:16, loss:23.314788818359375\n",
            "17\n",
            "step:17, loss:11.616443634033203\n",
            "18\n",
            "step:18, loss:31.019607543945312\n",
            "19\n",
            "step:19, loss:62.10037612915039\n",
            "20\n",
            "step:20, loss:19.194419860839844\n",
            "21\n",
            "step:21, loss:16.297271728515625\n",
            "22\n",
            "step:22, loss:45.01188278198242\n",
            "23\n",
            "step:23, loss:9.895166397094727\n",
            "24\n",
            "step:24, loss:61.57752227783203\n",
            "25\n",
            "step:25, loss:23.350975036621094\n",
            "26\n",
            "step:26, loss:18.10547637939453\n",
            "27\n",
            "step:27, loss:25.578834533691406\n",
            "28\n",
            "step:28, loss:11.458290100097656\n",
            "29\n",
            "step:29, loss:13.89958667755127\n",
            "30\n",
            "step:30, loss:30.952613830566406\n",
            "31\n",
            "step:31, loss:37.207801818847656\n",
            "32\n",
            "step:32, loss:13.06912612915039\n",
            "33\n",
            "step:33, loss:38.14781188964844\n",
            "34\n",
            "step:34, loss:18.381959915161133\n",
            "35\n",
            "step:35, loss:13.313774108886719\n",
            "36\n",
            "step:36, loss:8.692625045776367\n",
            "37\n",
            "step:37, loss:7.400949954986572\n",
            "38\n",
            "step:38, loss:48.18247604370117\n",
            "39\n",
            "step:39, loss:7.079430103302002\n",
            "40\n",
            "step:40, loss:27.944446563720703\n",
            "41\n",
            "step:41, loss:8.378108978271484\n",
            "42\n",
            "step:42, loss:31.44835090637207\n",
            "43\n",
            "step:43, loss:14.438173294067383\n",
            "44\n",
            "step:44, loss:37.869789123535156\n",
            "45\n",
            "step:45, loss:5.407057762145996\n",
            "46\n",
            "step:46, loss:19.67359161376953\n",
            "47\n",
            "step:47, loss:15.095369338989258\n",
            "48\n",
            "step:48, loss:23.822885513305664\n",
            "49\n",
            "step:49, loss:19.240367889404297\n",
            "50\n",
            "step:50, loss:11.892383575439453\n",
            "51\n",
            "step:51, loss:17.44229507446289\n",
            "52\n",
            "step:52, loss:25.28072738647461\n",
            "53\n",
            "step:53, loss:25.668556213378906\n",
            "54\n",
            "step:54, loss:48.271522521972656\n",
            "55\n",
            "step:55, loss:18.83057403564453\n",
            "56\n",
            "step:56, loss:10.315837860107422\n",
            "57\n",
            "step:57, loss:20.469324111938477\n",
            "58\n",
            "step:58, loss:16.772659301757812\n",
            "59\n",
            "step:59, loss:13.44549560546875\n",
            "60\n",
            "step:60, loss:16.397153854370117\n",
            "61\n",
            "step:61, loss:5.687475204467773\n",
            "62\n",
            "step:62, loss:12.668997764587402\n",
            "63\n",
            "step:63, loss:13.10871696472168\n",
            "64\n",
            "step:64, loss:11.39312744140625\n",
            "65\n",
            "step:65, loss:11.270240783691406\n",
            "66\n",
            "step:66, loss:14.87800121307373\n",
            "67\n",
            "step:67, loss:33.3900032043457\n",
            "68\n",
            "step:68, loss:18.645774841308594\n",
            "69\n",
            "step:69, loss:11.98859691619873\n",
            "8\n",
            "-----\n",
            "0\n",
            "step:0, loss:10.501020431518555\n",
            "1\n",
            "step:1, loss:10.946914672851562\n",
            "2\n",
            "step:2, loss:21.28727912902832\n",
            "3\n",
            "step:3, loss:11.083826065063477\n",
            "4\n",
            "step:4, loss:10.693442344665527\n",
            "5\n",
            "step:5, loss:9.225406646728516\n",
            "6\n",
            "step:6, loss:63.56827926635742\n",
            "7\n",
            "step:7, loss:74.11234283447266\n",
            "8\n",
            "step:8, loss:16.276029586791992\n",
            "9\n",
            "step:9, loss:14.911523818969727\n",
            "10\n",
            "step:10, loss:33.120540618896484\n",
            "11\n",
            "step:11, loss:18.142427444458008\n",
            "12\n",
            "step:12, loss:35.251243591308594\n",
            "13\n",
            "step:13, loss:10.648380279541016\n",
            "14\n",
            "step:14, loss:14.29463005065918\n",
            "15\n",
            "step:15, loss:7.556800842285156\n",
            "16\n",
            "step:16, loss:14.118526458740234\n",
            "17\n",
            "step:17, loss:20.884815216064453\n",
            "18\n",
            "step:18, loss:51.912620544433594\n",
            "19\n",
            "step:19, loss:24.839202880859375\n",
            "20\n",
            "step:20, loss:8.995065689086914\n",
            "21\n",
            "step:21, loss:10.163440704345703\n",
            "22\n",
            "step:22, loss:29.49441909790039\n",
            "23\n",
            "step:23, loss:7.361370086669922\n",
            "24\n",
            "step:24, loss:77.47750854492188\n",
            "25\n",
            "step:25, loss:14.694311141967773\n",
            "26\n",
            "step:26, loss:13.72272777557373\n",
            "27\n",
            "step:27, loss:17.21190643310547\n",
            "28\n",
            "step:28, loss:9.05885124206543\n",
            "29\n",
            "step:29, loss:14.630722999572754\n",
            "30\n",
            "step:30, loss:8.731138229370117\n",
            "31\n",
            "step:31, loss:9.939892768859863\n",
            "32\n",
            "step:32, loss:8.02308177947998\n",
            "33\n",
            "step:33, loss:31.467243194580078\n",
            "34\n",
            "step:34, loss:22.08936882019043\n",
            "35\n",
            "step:35, loss:12.317670822143555\n",
            "36\n",
            "step:36, loss:23.303680419921875\n",
            "37\n",
            "step:37, loss:4.019777774810791\n",
            "38\n",
            "step:38, loss:3.9955384731292725\n",
            "39\n",
            "step:39, loss:7.326812267303467\n",
            "40\n",
            "step:40, loss:19.87299156188965\n",
            "41\n",
            "step:41, loss:27.763198852539062\n",
            "42\n",
            "step:42, loss:17.004188537597656\n",
            "43\n",
            "step:43, loss:64.30973052978516\n",
            "44\n",
            "step:44, loss:33.355831146240234\n",
            "45\n",
            "step:45, loss:7.717516899108887\n",
            "46\n",
            "step:46, loss:71.09318542480469\n",
            "47\n",
            "step:47, loss:9.592866897583008\n",
            "48\n",
            "step:48, loss:13.686603546142578\n",
            "49\n",
            "step:49, loss:13.930778503417969\n",
            "50\n",
            "step:50, loss:8.67349624633789\n",
            "51\n",
            "step:51, loss:13.927489280700684\n",
            "52\n",
            "step:52, loss:13.768718719482422\n",
            "53\n",
            "step:53, loss:7.058109283447266\n",
            "54\n",
            "step:54, loss:10.086297988891602\n",
            "55\n",
            "step:55, loss:58.45911407470703\n",
            "56\n",
            "step:56, loss:13.540799140930176\n",
            "57\n",
            "step:57, loss:40.82155227661133\n",
            "58\n",
            "step:58, loss:30.042278289794922\n",
            "59\n",
            "step:59, loss:15.324455261230469\n",
            "60\n",
            "step:60, loss:16.391128540039062\n",
            "61\n",
            "step:61, loss:20.739601135253906\n",
            "62\n",
            "step:62, loss:17.162294387817383\n",
            "63\n",
            "step:63, loss:15.113058090209961\n",
            "64\n",
            "step:64, loss:31.278348922729492\n",
            "65\n",
            "step:65, loss:9.83558177947998\n",
            "66\n",
            "step:66, loss:16.809293746948242\n",
            "67\n",
            "step:67, loss:13.500633239746094\n",
            "68\n",
            "step:68, loss:22.780248641967773\n",
            "69\n",
            "step:69, loss:35.67022705078125\n",
            "9\n",
            "-----\n",
            "0\n",
            "step:0, loss:48.77455139160156\n",
            "1\n",
            "step:1, loss:13.947244644165039\n",
            "2\n",
            "step:2, loss:19.573238372802734\n",
            "3\n",
            "step:3, loss:13.927042007446289\n",
            "4\n",
            "step:4, loss:3.970226287841797\n",
            "5\n",
            "step:5, loss:3.9628236293792725\n",
            "6\n",
            "step:6, loss:13.537906646728516\n",
            "7\n",
            "step:7, loss:24.610107421875\n",
            "8\n",
            "step:8, loss:8.761261940002441\n",
            "9\n",
            "step:9, loss:71.76947021484375\n",
            "10\n",
            "step:10, loss:12.391361236572266\n",
            "11\n",
            "step:11, loss:10.379152297973633\n",
            "12\n",
            "step:12, loss:10.132001876831055\n",
            "13\n",
            "step:13, loss:28.99976348876953\n",
            "14\n",
            "step:14, loss:20.590513229370117\n",
            "15\n",
            "step:15, loss:14.857329368591309\n",
            "16\n",
            "step:16, loss:6.502671241760254\n",
            "17\n",
            "step:17, loss:11.212260246276855\n",
            "18\n",
            "step:18, loss:18.004417419433594\n",
            "19\n",
            "step:19, loss:6.235109329223633\n",
            "20\n",
            "step:20, loss:16.58505630493164\n",
            "21\n",
            "step:21, loss:11.54688835144043\n",
            "22\n",
            "step:22, loss:23.564123153686523\n",
            "23\n",
            "step:23, loss:18.43438148498535\n",
            "24\n",
            "step:24, loss:7.069788455963135\n",
            "25\n",
            "step:25, loss:70.64447021484375\n",
            "26\n",
            "step:26, loss:2.1877644062042236\n",
            "27\n",
            "step:27, loss:8.807658195495605\n",
            "28\n",
            "step:28, loss:52.53163146972656\n",
            "29\n",
            "step:29, loss:8.859588623046875\n",
            "30\n",
            "step:30, loss:10.505104064941406\n",
            "31\n",
            "step:31, loss:23.691143035888672\n",
            "32\n",
            "step:32, loss:11.27261734008789\n",
            "33\n",
            "step:33, loss:8.801223754882812\n",
            "34\n",
            "step:34, loss:10.828699111938477\n",
            "35\n",
            "step:35, loss:16.799823760986328\n",
            "36\n",
            "step:36, loss:5.632663726806641\n",
            "37\n",
            "step:37, loss:9.541208267211914\n",
            "38\n",
            "step:38, loss:10.783733367919922\n",
            "39\n",
            "step:39, loss:7.304072380065918\n",
            "40\n",
            "step:40, loss:65.81802368164062\n",
            "41\n",
            "step:41, loss:86.96086883544922\n",
            "42\n",
            "step:42, loss:17.733680725097656\n",
            "43\n",
            "step:43, loss:3.8958840370178223\n",
            "44\n",
            "step:44, loss:9.466365814208984\n",
            "45\n",
            "step:45, loss:14.149320602416992\n",
            "46\n",
            "step:46, loss:14.47476577758789\n",
            "47\n",
            "step:47, loss:13.496844291687012\n",
            "48\n",
            "step:48, loss:18.528453826904297\n",
            "49\n",
            "step:49, loss:8.749659538269043\n",
            "50\n",
            "step:50, loss:6.501722812652588\n",
            "51\n",
            "step:51, loss:8.706298828125\n",
            "52\n",
            "step:52, loss:58.19639587402344\n",
            "53\n",
            "step:53, loss:13.561324119567871\n",
            "54\n",
            "step:54, loss:15.452194213867188\n",
            "55\n",
            "step:55, loss:7.777697563171387\n",
            "56\n",
            "step:56, loss:6.755786895751953\n",
            "57\n",
            "step:57, loss:22.838350296020508\n",
            "58\n",
            "step:58, loss:34.24050521850586\n",
            "59\n",
            "step:59, loss:35.38382339477539\n",
            "60\n",
            "step:60, loss:6.8286566734313965\n",
            "61\n",
            "step:61, loss:14.088374137878418\n",
            "62\n",
            "step:62, loss:14.394390106201172\n",
            "63\n",
            "step:63, loss:8.186830520629883\n",
            "64\n",
            "step:64, loss:19.121856689453125\n",
            "65\n",
            "step:65, loss:9.836932182312012\n",
            "66\n",
            "step:66, loss:14.229751586914062\n",
            "67\n",
            "step:67, loss:19.392642974853516\n",
            "68\n",
            "step:68, loss:11.540735244750977\n",
            "69\n",
            "step:69, loss:5.561764717102051\n",
            "10\n",
            "-----\n",
            "0\n",
            "step:0, loss:15.699559211730957\n",
            "1\n",
            "step:1, loss:39.951927185058594\n",
            "2\n",
            "step:2, loss:30.132213592529297\n",
            "3\n",
            "step:3, loss:19.0566349029541\n",
            "4\n",
            "step:4, loss:11.570837020874023\n",
            "5\n",
            "step:5, loss:36.31861114501953\n",
            "6\n",
            "step:6, loss:23.573945999145508\n",
            "7\n",
            "step:7, loss:10.468854904174805\n",
            "8\n",
            "step:8, loss:4.1903486251831055\n",
            "9\n",
            "step:9, loss:6.367720603942871\n",
            "10\n",
            "step:10, loss:29.459228515625\n",
            "11\n",
            "step:11, loss:6.263338565826416\n",
            "12\n",
            "step:12, loss:10.171290397644043\n",
            "13\n",
            "step:13, loss:13.638336181640625\n",
            "14\n",
            "step:14, loss:9.975808143615723\n",
            "15\n",
            "step:15, loss:46.1939811706543\n",
            "16\n",
            "step:16, loss:12.368096351623535\n",
            "17\n",
            "step:17, loss:9.467353820800781\n",
            "18\n",
            "step:18, loss:6.3887176513671875\n",
            "19\n",
            "step:19, loss:15.15913200378418\n",
            "20\n",
            "step:20, loss:10.359176635742188\n",
            "21\n",
            "step:21, loss:10.213277816772461\n",
            "22\n",
            "step:22, loss:8.597935676574707\n",
            "23\n",
            "step:23, loss:12.036422729492188\n",
            "24\n",
            "step:24, loss:17.666555404663086\n",
            "25\n",
            "step:25, loss:87.525146484375\n",
            "26\n",
            "step:26, loss:41.78488540649414\n",
            "27\n",
            "step:27, loss:17.098527908325195\n",
            "28\n",
            "step:28, loss:18.1364688873291\n",
            "29\n",
            "step:29, loss:5.8582234382629395\n",
            "30\n",
            "step:30, loss:7.111761093139648\n",
            "31\n",
            "step:31, loss:38.0086784362793\n",
            "32\n",
            "step:32, loss:8.941803932189941\n",
            "33\n",
            "step:33, loss:15.5894775390625\n",
            "34\n",
            "step:34, loss:19.982824325561523\n",
            "35\n",
            "step:35, loss:54.22763442993164\n",
            "36\n",
            "step:36, loss:9.793231964111328\n",
            "37\n",
            "step:37, loss:34.74530029296875\n",
            "38\n",
            "step:38, loss:7.1006999015808105\n",
            "39\n",
            "step:39, loss:25.277559280395508\n",
            "40\n",
            "step:40, loss:4.681671619415283\n",
            "41\n",
            "step:41, loss:55.85960388183594\n",
            "42\n",
            "step:42, loss:6.357845306396484\n",
            "43\n",
            "step:43, loss:6.520007133483887\n",
            "44\n",
            "step:44, loss:14.587945938110352\n",
            "45\n",
            "step:45, loss:8.15041732788086\n",
            "46\n",
            "step:46, loss:19.00600814819336\n",
            "47\n",
            "step:47, loss:30.054401397705078\n",
            "48\n",
            "step:48, loss:7.06341552734375\n",
            "49\n",
            "step:49, loss:5.178292274475098\n",
            "50\n",
            "step:50, loss:9.35156536102295\n",
            "51\n",
            "step:51, loss:14.56959056854248\n",
            "52\n",
            "step:52, loss:5.831284523010254\n",
            "53\n",
            "step:53, loss:10.974929809570312\n",
            "54\n",
            "step:54, loss:29.226058959960938\n",
            "55\n",
            "step:55, loss:12.44580078125\n",
            "56\n",
            "step:56, loss:9.113128662109375\n",
            "57\n",
            "step:57, loss:13.915143013000488\n",
            "58\n",
            "step:58, loss:6.3055524826049805\n",
            "59\n",
            "step:59, loss:10.791857719421387\n",
            "60\n",
            "step:60, loss:4.6455464363098145\n",
            "61\n",
            "step:61, loss:8.998048782348633\n",
            "62\n",
            "step:62, loss:8.457389831542969\n",
            "63\n",
            "step:63, loss:6.169318199157715\n",
            "64\n",
            "step:64, loss:10.79773998260498\n",
            "65\n",
            "step:65, loss:6.224538803100586\n",
            "66\n",
            "step:66, loss:9.989850044250488\n",
            "67\n",
            "step:67, loss:23.225370407104492\n",
            "68\n",
            "step:68, loss:2.9949545860290527\n",
            "69\n",
            "step:69, loss:6.208132743835449\n",
            "11\n",
            "-----\n",
            "0\n",
            "step:0, loss:29.194772720336914\n",
            "1\n",
            "step:1, loss:87.51895141601562\n",
            "2\n",
            "step:2, loss:7.271031379699707\n",
            "3\n",
            "step:3, loss:3.7746963500976562\n",
            "4\n",
            "step:4, loss:5.480657577514648\n",
            "5\n",
            "step:5, loss:6.805792331695557\n",
            "6\n",
            "step:6, loss:4.813295364379883\n",
            "7\n",
            "step:7, loss:5.991215229034424\n",
            "8\n",
            "step:8, loss:28.55233383178711\n",
            "9\n",
            "step:9, loss:7.208646774291992\n",
            "10\n",
            "step:10, loss:12.4021577835083\n",
            "11\n",
            "step:11, loss:24.31632423400879\n",
            "12\n",
            "step:12, loss:58.56769561767578\n",
            "13\n",
            "step:13, loss:4.079566478729248\n",
            "14\n",
            "step:14, loss:8.915383338928223\n",
            "15\n",
            "step:15, loss:4.755954265594482\n",
            "16\n",
            "step:16, loss:8.313817977905273\n",
            "17\n",
            "step:17, loss:13.582334518432617\n",
            "18\n",
            "step:18, loss:15.49489974975586\n",
            "19\n",
            "step:19, loss:18.190563201904297\n",
            "20\n",
            "step:20, loss:43.419979095458984\n",
            "21\n",
            "step:21, loss:13.916851997375488\n",
            "22\n",
            "step:22, loss:17.084136962890625\n",
            "23\n",
            "step:23, loss:30.109088897705078\n",
            "24\n",
            "step:24, loss:4.664510726928711\n",
            "25\n",
            "step:25, loss:11.667767524719238\n",
            "26\n",
            "step:26, loss:8.149417877197266\n",
            "27\n",
            "step:27, loss:9.221406936645508\n",
            "28\n",
            "step:28, loss:25.054323196411133\n",
            "29\n",
            "step:29, loss:12.714179992675781\n",
            "30\n",
            "step:30, loss:3.873063087463379\n",
            "31\n",
            "step:31, loss:8.308218002319336\n",
            "32\n",
            "step:32, loss:25.159542083740234\n",
            "33\n",
            "step:33, loss:13.145288467407227\n",
            "34\n",
            "step:34, loss:3.643828868865967\n",
            "35\n",
            "step:35, loss:7.794367790222168\n",
            "36\n",
            "step:36, loss:24.89634132385254\n",
            "37\n",
            "step:37, loss:8.148917198181152\n",
            "38\n",
            "step:38, loss:12.165613174438477\n",
            "39\n",
            "step:39, loss:3.476910352706909\n",
            "40\n",
            "step:40, loss:6.519633769989014\n",
            "41\n",
            "step:41, loss:26.567468643188477\n",
            "42\n",
            "step:42, loss:15.832672119140625\n",
            "43\n",
            "step:43, loss:5.73917293548584\n",
            "44\n",
            "step:44, loss:7.419427871704102\n",
            "45\n",
            "step:45, loss:11.916603088378906\n",
            "46\n",
            "step:46, loss:15.335526466369629\n",
            "47\n",
            "step:47, loss:62.33026123046875\n",
            "48\n",
            "step:48, loss:5.463901519775391\n",
            "49\n",
            "step:49, loss:9.061972618103027\n",
            "50\n",
            "step:50, loss:13.186395645141602\n",
            "51\n",
            "step:51, loss:55.640838623046875\n",
            "52\n",
            "step:52, loss:26.303325653076172\n",
            "53\n",
            "step:53, loss:6.042299270629883\n",
            "54\n",
            "step:54, loss:8.84168815612793\n",
            "55\n",
            "step:55, loss:9.567097663879395\n",
            "56\n",
            "step:56, loss:12.420883178710938\n",
            "57\n",
            "step:57, loss:25.592920303344727\n",
            "58\n",
            "step:58, loss:9.582883834838867\n",
            "59\n",
            "step:59, loss:13.93215560913086\n",
            "60\n",
            "step:60, loss:10.544792175292969\n",
            "61\n",
            "step:61, loss:25.09018898010254\n",
            "62\n",
            "step:62, loss:9.047662734985352\n",
            "63\n",
            "step:63, loss:3.0313754081726074\n",
            "64\n",
            "step:64, loss:7.594122886657715\n",
            "65\n",
            "step:65, loss:8.612980842590332\n",
            "66\n",
            "step:66, loss:6.170544624328613\n",
            "67\n",
            "step:67, loss:10.1876859664917\n",
            "68\n",
            "step:68, loss:10.235629081726074\n",
            "69\n",
            "step:69, loss:26.17200469970703\n",
            "12\n",
            "-----\n",
            "0\n",
            "step:0, loss:5.953695297241211\n",
            "1\n",
            "step:1, loss:20.113794326782227\n",
            "2\n",
            "step:2, loss:10.647174835205078\n",
            "3\n",
            "step:3, loss:5.236278533935547\n",
            "4\n",
            "step:4, loss:5.882737159729004\n",
            "5\n",
            "step:5, loss:5.124298572540283\n",
            "6\n",
            "step:6, loss:4.948766231536865\n",
            "7\n",
            "step:7, loss:6.620858669281006\n",
            "8\n",
            "step:8, loss:31.42447280883789\n",
            "9\n",
            "step:9, loss:42.408504486083984\n",
            "10\n",
            "step:10, loss:17.86449432373047\n",
            "11\n",
            "step:11, loss:13.120278358459473\n",
            "12\n",
            "step:12, loss:43.155094146728516\n",
            "13\n",
            "step:13, loss:7.053915023803711\n",
            "14\n",
            "step:14, loss:7.596291542053223\n",
            "15\n",
            "step:15, loss:10.926751136779785\n",
            "16\n",
            "step:16, loss:8.27552604675293\n",
            "17\n",
            "step:17, loss:29.046213150024414\n",
            "18\n",
            "step:18, loss:4.844494819641113\n",
            "19\n",
            "step:19, loss:5.523036956787109\n",
            "20\n",
            "step:20, loss:21.44373321533203\n",
            "21\n",
            "step:21, loss:7.434926986694336\n",
            "22\n",
            "step:22, loss:4.34077262878418\n",
            "23\n",
            "step:23, loss:15.814081192016602\n",
            "24\n",
            "step:24, loss:4.781940460205078\n",
            "25\n",
            "step:25, loss:18.66857147216797\n",
            "26\n",
            "step:26, loss:9.448217391967773\n",
            "27\n",
            "step:27, loss:3.1073412895202637\n",
            "28\n",
            "step:28, loss:22.412111282348633\n",
            "29\n",
            "step:29, loss:44.56231689453125\n",
            "30\n",
            "step:30, loss:11.061355590820312\n",
            "31\n",
            "step:31, loss:12.045666694641113\n",
            "32\n",
            "step:32, loss:10.73824405670166\n",
            "33\n",
            "step:33, loss:26.61846160888672\n",
            "34\n",
            "step:34, loss:4.933821678161621\n",
            "35\n",
            "step:35, loss:24.165307998657227\n",
            "36\n",
            "step:36, loss:10.217727661132812\n",
            "37\n",
            "step:37, loss:15.483057975769043\n",
            "38\n",
            "step:38, loss:71.88536071777344\n",
            "39\n",
            "step:39, loss:7.7826738357543945\n",
            "40\n",
            "step:40, loss:6.128756046295166\n",
            "41\n",
            "step:41, loss:9.825996398925781\n",
            "42\n",
            "step:42, loss:11.100918769836426\n",
            "43\n",
            "step:43, loss:8.96457290649414\n",
            "44\n",
            "step:44, loss:7.763650894165039\n",
            "45\n",
            "step:45, loss:5.209012985229492\n",
            "46\n",
            "step:46, loss:10.183411598205566\n",
            "47\n",
            "step:47, loss:21.316776275634766\n",
            "48\n",
            "step:48, loss:8.34197998046875\n",
            "49\n",
            "step:49, loss:7.876203536987305\n",
            "50\n",
            "step:50, loss:43.98280715942383\n",
            "51\n",
            "step:51, loss:9.729801177978516\n",
            "52\n",
            "step:52, loss:47.225955963134766\n",
            "53\n",
            "step:53, loss:9.897590637207031\n",
            "54\n",
            "step:54, loss:4.830207347869873\n",
            "55\n",
            "step:55, loss:6.851020812988281\n",
            "56\n",
            "step:56, loss:16.143356323242188\n",
            "57\n",
            "step:57, loss:12.481290817260742\n",
            "58\n",
            "step:58, loss:4.711308002471924\n",
            "59\n",
            "step:59, loss:19.400880813598633\n",
            "60\n",
            "step:60, loss:11.502473831176758\n",
            "61\n",
            "step:61, loss:12.417274475097656\n",
            "62\n",
            "step:62, loss:26.580020904541016\n",
            "63\n",
            "step:63, loss:3.5955758094787598\n",
            "64\n",
            "step:64, loss:12.290502548217773\n",
            "65\n",
            "step:65, loss:6.431910991668701\n",
            "66\n",
            "step:66, loss:41.645111083984375\n",
            "67\n",
            "step:67, loss:9.190706253051758\n",
            "68\n",
            "step:68, loss:5.882488250732422\n",
            "69\n",
            "step:69, loss:6.456062316894531\n",
            "13\n",
            "-----\n",
            "0\n",
            "step:0, loss:11.72053337097168\n",
            "1\n",
            "step:1, loss:4.611550331115723\n",
            "2\n",
            "step:2, loss:6.240323066711426\n",
            "3\n",
            "step:3, loss:5.641209602355957\n",
            "4\n",
            "step:4, loss:13.691622734069824\n",
            "5\n",
            "step:5, loss:16.25994873046875\n",
            "6\n",
            "step:6, loss:28.60759735107422\n",
            "7\n",
            "step:7, loss:3.9558308124542236\n",
            "8\n",
            "step:8, loss:5.293455123901367\n",
            "9\n",
            "step:9, loss:8.151848793029785\n",
            "10\n",
            "step:10, loss:6.230007171630859\n",
            "11\n",
            "step:11, loss:69.33306884765625\n",
            "12\n",
            "step:12, loss:11.923393249511719\n",
            "13\n",
            "step:13, loss:18.25232696533203\n",
            "14\n",
            "step:14, loss:24.00092124938965\n",
            "15\n",
            "step:15, loss:7.101694107055664\n",
            "16\n",
            "step:16, loss:4.824184417724609\n",
            "17\n",
            "step:17, loss:11.415729522705078\n",
            "18\n",
            "step:18, loss:50.372093200683594\n",
            "19\n",
            "step:19, loss:5.706919193267822\n",
            "20\n",
            "step:20, loss:12.406564712524414\n",
            "21\n",
            "step:21, loss:12.446946144104004\n",
            "22\n",
            "step:22, loss:2.5909616947174072\n",
            "23\n",
            "step:23, loss:3.3515231609344482\n",
            "24\n",
            "step:24, loss:8.418693542480469\n",
            "25\n",
            "step:25, loss:6.699359893798828\n",
            "26\n",
            "step:26, loss:4.250923156738281\n",
            "27\n",
            "step:27, loss:7.784026622772217\n",
            "28\n",
            "step:28, loss:28.04012680053711\n",
            "29\n",
            "step:29, loss:22.643754959106445\n",
            "30\n",
            "step:30, loss:18.73712158203125\n",
            "31\n",
            "step:31, loss:12.889618873596191\n",
            "32\n",
            "step:32, loss:27.130800247192383\n",
            "33\n",
            "step:33, loss:14.036355972290039\n",
            "34\n",
            "step:34, loss:7.036670684814453\n",
            "35\n",
            "step:35, loss:50.27762985229492\n",
            "36\n",
            "step:36, loss:7.050286769866943\n",
            "37\n",
            "step:37, loss:4.842526435852051\n",
            "38\n",
            "step:38, loss:13.467387199401855\n",
            "39\n",
            "step:39, loss:9.77109432220459\n",
            "40\n",
            "step:40, loss:6.644871711730957\n",
            "41\n",
            "step:41, loss:6.507102966308594\n",
            "42\n",
            "step:42, loss:8.763303756713867\n",
            "43\n",
            "step:43, loss:5.031854629516602\n",
            "44\n",
            "step:44, loss:3.0198116302490234\n",
            "45\n",
            "step:45, loss:13.922395706176758\n",
            "46\n",
            "step:46, loss:8.495575904846191\n",
            "47\n",
            "step:47, loss:5.816679954528809\n",
            "48\n",
            "step:48, loss:15.967412948608398\n",
            "49\n",
            "step:49, loss:5.709246635437012\n",
            "50\n",
            "step:50, loss:4.462247848510742\n",
            "51\n",
            "step:51, loss:6.380842208862305\n",
            "52\n",
            "step:52, loss:19.868118286132812\n",
            "53\n",
            "step:53, loss:52.28565216064453\n",
            "54\n",
            "step:54, loss:4.8422956466674805\n",
            "55\n",
            "step:55, loss:5.000133514404297\n",
            "56\n",
            "step:56, loss:8.101856231689453\n",
            "57\n",
            "step:57, loss:33.57661437988281\n",
            "58\n",
            "step:58, loss:40.740478515625\n",
            "59\n",
            "step:59, loss:17.412118911743164\n",
            "60\n",
            "step:60, loss:4.8738203048706055\n",
            "61\n",
            "step:61, loss:8.86452865600586\n",
            "62\n",
            "step:62, loss:2.620007276535034\n",
            "63\n",
            "step:63, loss:4.590041637420654\n",
            "64\n",
            "step:64, loss:3.6520895957946777\n",
            "65\n",
            "step:65, loss:11.607433319091797\n",
            "66\n",
            "step:66, loss:12.599617958068848\n",
            "67\n",
            "step:67, loss:10.607427597045898\n",
            "68\n",
            "step:68, loss:18.712627410888672\n",
            "69\n",
            "step:69, loss:11.817222595214844\n",
            "14\n",
            "-----\n",
            "0\n",
            "step:0, loss:6.527658462524414\n",
            "1\n",
            "step:1, loss:24.959930419921875\n",
            "2\n",
            "step:2, loss:15.096985816955566\n",
            "3\n",
            "step:3, loss:4.89781379699707\n",
            "4\n",
            "step:4, loss:24.41613006591797\n",
            "5\n",
            "step:5, loss:42.608131408691406\n",
            "6\n",
            "step:6, loss:5.856515884399414\n",
            "7\n",
            "step:7, loss:9.615314483642578\n",
            "8\n",
            "step:8, loss:4.515390396118164\n",
            "9\n",
            "step:9, loss:4.070476055145264\n",
            "10\n",
            "step:10, loss:7.165414810180664\n",
            "11\n",
            "step:11, loss:4.217459201812744\n",
            "12\n",
            "step:12, loss:31.167877197265625\n",
            "13\n",
            "step:13, loss:13.542399406433105\n",
            "14\n",
            "step:14, loss:6.889198303222656\n",
            "15\n",
            "step:15, loss:4.2897186279296875\n",
            "16\n",
            "step:16, loss:7.268102169036865\n",
            "17\n",
            "step:17, loss:24.847959518432617\n",
            "18\n",
            "step:18, loss:16.23442268371582\n",
            "19\n",
            "step:19, loss:5.1137495040893555\n",
            "20\n",
            "step:20, loss:12.728130340576172\n",
            "21\n",
            "step:21, loss:17.619449615478516\n",
            "22\n",
            "step:22, loss:37.65092468261719\n",
            "23\n",
            "step:23, loss:18.478275299072266\n",
            "24\n",
            "step:24, loss:16.494613647460938\n",
            "25\n",
            "step:25, loss:8.291271209716797\n",
            "26\n",
            "step:26, loss:5.353501796722412\n",
            "27\n",
            "step:27, loss:63.48235321044922\n",
            "28\n",
            "step:28, loss:30.121809005737305\n",
            "29\n",
            "step:29, loss:7.387001037597656\n",
            "30\n",
            "step:30, loss:17.543458938598633\n",
            "31\n",
            "step:31, loss:4.332060813903809\n",
            "32\n",
            "step:32, loss:12.512252807617188\n",
            "33\n",
            "step:33, loss:6.12434196472168\n",
            "34\n",
            "step:34, loss:9.580358505249023\n",
            "35\n",
            "step:35, loss:4.052624702453613\n",
            "36\n",
            "step:36, loss:11.771812438964844\n",
            "37\n",
            "step:37, loss:40.001434326171875\n",
            "38\n",
            "step:38, loss:7.164029121398926\n",
            "39\n",
            "step:39, loss:5.361636638641357\n",
            "40\n",
            "step:40, loss:11.45268440246582\n",
            "41\n",
            "step:41, loss:7.151692867279053\n",
            "42\n",
            "step:42, loss:10.813995361328125\n",
            "43\n",
            "step:43, loss:3.9596569538116455\n",
            "44\n",
            "step:44, loss:20.45381736755371\n",
            "45\n",
            "step:45, loss:8.86030387878418\n",
            "46\n",
            "step:46, loss:5.507322311401367\n",
            "47\n",
            "step:47, loss:26.135156631469727\n",
            "48\n",
            "step:48, loss:51.19690704345703\n",
            "49\n",
            "step:49, loss:18.565359115600586\n",
            "50\n",
            "step:50, loss:3.2092490196228027\n",
            "51\n",
            "step:51, loss:4.3858795166015625\n",
            "52\n",
            "step:52, loss:5.692230224609375\n",
            "53\n",
            "step:53, loss:10.538980484008789\n",
            "54\n",
            "step:54, loss:12.08989143371582\n",
            "55\n",
            "step:55, loss:4.4928879737854\n",
            "56\n",
            "step:56, loss:5.559572219848633\n",
            "57\n",
            "step:57, loss:8.169130325317383\n",
            "58\n",
            "step:58, loss:7.931432247161865\n",
            "59\n",
            "step:59, loss:2.375952959060669\n",
            "60\n",
            "step:60, loss:15.250588417053223\n",
            "61\n",
            "step:61, loss:5.383868217468262\n",
            "62\n",
            "step:62, loss:5.035042762756348\n",
            "63\n",
            "step:63, loss:6.027839660644531\n",
            "64\n",
            "step:64, loss:6.31955623626709\n",
            "65\n",
            "step:65, loss:3.857705593109131\n",
            "66\n",
            "step:66, loss:7.758457183837891\n",
            "67\n",
            "step:67, loss:3.4847872257232666\n",
            "68\n",
            "step:68, loss:4.5743937492370605\n",
            "69\n",
            "step:69, loss:2.536968231201172\n",
            "15\n",
            "-----\n",
            "0\n",
            "step:0, loss:1.6868343353271484\n",
            "1\n",
            "step:1, loss:3.9613704681396484\n",
            "2\n",
            "step:2, loss:18.626712799072266\n",
            "3\n",
            "step:3, loss:7.737493515014648\n",
            "4\n",
            "step:4, loss:16.40738296508789\n",
            "5\n",
            "step:5, loss:6.2177534103393555\n",
            "6\n",
            "step:6, loss:2.694936990737915\n",
            "7\n",
            "step:7, loss:7.248481750488281\n",
            "8\n",
            "step:8, loss:3.027085304260254\n",
            "9\n",
            "step:9, loss:31.907854080200195\n",
            "10\n",
            "step:10, loss:7.173393249511719\n",
            "11\n",
            "step:11, loss:1.7485065460205078\n",
            "12\n",
            "step:12, loss:17.7940731048584\n",
            "13\n",
            "step:13, loss:10.419900894165039\n",
            "14\n",
            "step:14, loss:2.7144298553466797\n",
            "15\n",
            "step:15, loss:25.111248016357422\n",
            "16\n",
            "step:16, loss:27.288127899169922\n",
            "17\n",
            "step:17, loss:3.92399525642395\n",
            "18\n",
            "step:18, loss:6.517638683319092\n",
            "19\n",
            "step:19, loss:12.55760383605957\n",
            "20\n",
            "step:20, loss:4.570173263549805\n",
            "21\n",
            "step:21, loss:4.678989887237549\n",
            "22\n",
            "step:22, loss:13.498089790344238\n",
            "23\n",
            "step:23, loss:2.660426139831543\n",
            "24\n",
            "step:24, loss:15.458044052124023\n",
            "25\n",
            "step:25, loss:6.772310256958008\n",
            "26\n",
            "step:26, loss:65.35612487792969\n",
            "27\n",
            "step:27, loss:7.427046298980713\n",
            "28\n",
            "step:28, loss:3.5225934982299805\n",
            "29\n",
            "step:29, loss:2.688202381134033\n",
            "30\n",
            "step:30, loss:5.860950946807861\n",
            "31\n",
            "step:31, loss:6.560269832611084\n",
            "32\n",
            "step:32, loss:37.32571792602539\n",
            "33\n",
            "step:33, loss:11.667196273803711\n",
            "34\n",
            "step:34, loss:19.80290985107422\n",
            "35\n",
            "step:35, loss:63.36163330078125\n",
            "36\n",
            "step:36, loss:3.822178840637207\n",
            "37\n",
            "step:37, loss:6.447205543518066\n",
            "38\n",
            "step:38, loss:6.842855453491211\n",
            "39\n",
            "step:39, loss:3.7699363231658936\n",
            "40\n",
            "step:40, loss:5.404069900512695\n",
            "41\n",
            "step:41, loss:9.848605155944824\n",
            "42\n",
            "step:42, loss:12.652441024780273\n",
            "43\n",
            "step:43, loss:15.883968353271484\n",
            "44\n",
            "step:44, loss:18.296995162963867\n",
            "45\n",
            "step:45, loss:3.897529125213623\n",
            "46\n",
            "step:46, loss:12.792914390563965\n",
            "47\n",
            "step:47, loss:4.263756275177002\n",
            "48\n",
            "step:48, loss:48.99721908569336\n",
            "49\n",
            "step:49, loss:43.083465576171875\n",
            "50\n",
            "step:50, loss:4.846014976501465\n",
            "51\n",
            "step:51, loss:3.25496244430542\n",
            "52\n",
            "step:52, loss:4.410952568054199\n",
            "53\n",
            "step:53, loss:7.878233909606934\n",
            "54\n",
            "step:54, loss:10.531118392944336\n",
            "55\n",
            "step:55, loss:5.918975353240967\n",
            "56\n",
            "step:56, loss:3.782447338104248\n",
            "57\n",
            "step:57, loss:17.631427764892578\n",
            "58\n",
            "step:58, loss:5.638431549072266\n",
            "59\n",
            "step:59, loss:1.6695507764816284\n",
            "60\n",
            "step:60, loss:3.9964523315429688\n",
            "61\n",
            "step:61, loss:8.509868621826172\n",
            "62\n",
            "step:62, loss:5.604994297027588\n",
            "63\n",
            "step:63, loss:21.534481048583984\n",
            "64\n",
            "step:64, loss:19.692224502563477\n",
            "65\n",
            "step:65, loss:2.135164260864258\n",
            "66\n",
            "step:66, loss:4.265251159667969\n",
            "67\n",
            "step:67, loss:6.772904396057129\n",
            "68\n",
            "step:68, loss:9.209304809570312\n",
            "69\n",
            "step:69, loss:18.23236846923828\n",
            "16\n",
            "-----\n",
            "0\n",
            "step:0, loss:39.250579833984375\n",
            "1\n",
            "step:1, loss:15.85055160522461\n",
            "2\n",
            "step:2, loss:3.1497323513031006\n",
            "3\n",
            "step:3, loss:10.288677215576172\n",
            "4\n",
            "step:4, loss:32.6132698059082\n",
            "5\n",
            "step:5, loss:5.663890838623047\n",
            "6\n",
            "step:6, loss:7.204720973968506\n",
            "7\n",
            "step:7, loss:26.683889389038086\n",
            "8\n",
            "step:8, loss:3.0787441730499268\n",
            "9\n",
            "step:9, loss:2.945309638977051\n",
            "10\n",
            "step:10, loss:15.844786643981934\n",
            "11\n",
            "step:11, loss:3.9170193672180176\n",
            "12\n",
            "step:12, loss:3.45469331741333\n",
            "13\n",
            "step:13, loss:8.068814277648926\n",
            "14\n",
            "step:14, loss:25.749217987060547\n",
            "15\n",
            "step:15, loss:5.194775104522705\n",
            "16\n",
            "step:16, loss:4.438529968261719\n",
            "17\n",
            "step:17, loss:14.843070983886719\n",
            "18\n",
            "step:18, loss:14.818887710571289\n",
            "19\n",
            "step:19, loss:37.440284729003906\n",
            "20\n",
            "step:20, loss:5.454416275024414\n",
            "21\n",
            "step:21, loss:8.704380989074707\n",
            "22\n",
            "step:22, loss:6.914245128631592\n",
            "23\n",
            "step:23, loss:7.116624355316162\n",
            "24\n",
            "step:24, loss:25.863075256347656\n",
            "25\n",
            "step:25, loss:5.349449634552002\n",
            "26\n",
            "step:26, loss:6.084547996520996\n",
            "27\n",
            "step:27, loss:11.132890701293945\n",
            "28\n",
            "step:28, loss:3.6894609928131104\n",
            "29\n",
            "step:29, loss:19.714462280273438\n",
            "30\n",
            "step:30, loss:9.003692626953125\n",
            "31\n",
            "step:31, loss:27.611310958862305\n",
            "32\n",
            "step:32, loss:5.926974296569824\n",
            "33\n",
            "step:33, loss:7.191457748413086\n",
            "34\n",
            "step:34, loss:9.094928741455078\n",
            "35\n",
            "step:35, loss:3.749086380004883\n",
            "36\n",
            "step:36, loss:38.129337310791016\n",
            "37\n",
            "step:37, loss:11.090925216674805\n",
            "38\n",
            "step:38, loss:44.08304214477539\n",
            "39\n",
            "step:39, loss:2.21614408493042\n",
            "40\n",
            "step:40, loss:5.144237518310547\n",
            "41\n",
            "step:41, loss:8.706243515014648\n",
            "42\n",
            "step:42, loss:4.650149822235107\n",
            "43\n",
            "step:43, loss:14.98680305480957\n",
            "44\n",
            "step:44, loss:6.017874240875244\n",
            "45\n",
            "step:45, loss:5.455953121185303\n",
            "46\n",
            "step:46, loss:6.069489479064941\n",
            "47\n",
            "step:47, loss:2.813185214996338\n",
            "48\n",
            "step:48, loss:7.777287483215332\n",
            "49\n",
            "step:49, loss:14.866681098937988\n",
            "50\n",
            "step:50, loss:7.38407039642334\n",
            "51\n",
            "step:51, loss:6.576458930969238\n",
            "52\n",
            "step:52, loss:3.6272072792053223\n",
            "53\n",
            "step:53, loss:4.967136383056641\n",
            "54\n",
            "step:54, loss:3.6828508377075195\n",
            "55\n",
            "step:55, loss:16.169198989868164\n",
            "56\n",
            "step:56, loss:4.107071399688721\n",
            "57\n",
            "step:57, loss:3.22788667678833\n",
            "58\n",
            "step:58, loss:66.25775146484375\n",
            "59\n",
            "step:59, loss:2.9488613605499268\n",
            "60\n",
            "step:60, loss:3.9320921897888184\n",
            "61\n",
            "step:61, loss:11.171302795410156\n",
            "62\n",
            "step:62, loss:5.745235919952393\n",
            "63\n",
            "step:63, loss:6.570680141448975\n",
            "64\n",
            "step:64, loss:2.988168239593506\n",
            "65\n",
            "step:65, loss:4.4259419441223145\n",
            "66\n",
            "step:66, loss:2.5670835971832275\n",
            "67\n",
            "step:67, loss:13.789082527160645\n",
            "68\n",
            "step:68, loss:4.217219829559326\n",
            "69\n",
            "step:69, loss:45.44495391845703\n",
            "17\n",
            "-----\n",
            "0\n",
            "step:0, loss:3.1092071533203125\n",
            "1\n",
            "step:1, loss:4.650606155395508\n",
            "2\n",
            "step:2, loss:5.825979232788086\n",
            "3\n",
            "step:3, loss:4.773833274841309\n",
            "4\n",
            "step:4, loss:13.615036010742188\n",
            "5\n",
            "step:5, loss:7.5460076332092285\n",
            "6\n",
            "step:6, loss:13.204361915588379\n",
            "7\n",
            "step:7, loss:3.1521525382995605\n",
            "8\n",
            "step:8, loss:16.148235321044922\n",
            "9\n",
            "step:9, loss:56.051719665527344\n",
            "10\n",
            "step:10, loss:5.626416206359863\n",
            "11\n",
            "step:11, loss:5.561583995819092\n",
            "12\n",
            "step:12, loss:3.342047691345215\n",
            "13\n",
            "step:13, loss:8.854673385620117\n",
            "14\n",
            "step:14, loss:34.03680419921875\n",
            "15\n",
            "step:15, loss:15.296869277954102\n",
            "16\n",
            "step:16, loss:23.534652709960938\n",
            "17\n",
            "step:17, loss:32.60664367675781\n",
            "18\n",
            "step:18, loss:19.290023803710938\n",
            "19\n",
            "step:19, loss:12.93533706665039\n",
            "20\n",
            "step:20, loss:7.147284507751465\n",
            "21\n",
            "step:21, loss:5.604248046875\n",
            "22\n",
            "step:22, loss:3.65964412689209\n",
            "23\n",
            "step:23, loss:6.441825866699219\n",
            "24\n",
            "step:24, loss:7.947901725769043\n",
            "25\n",
            "step:25, loss:10.146759033203125\n",
            "26\n",
            "step:26, loss:15.845026016235352\n",
            "27\n",
            "step:27, loss:7.695746898651123\n",
            "28\n",
            "step:28, loss:4.416570663452148\n",
            "29\n",
            "step:29, loss:3.129117727279663\n",
            "30\n",
            "step:30, loss:5.469327449798584\n",
            "31\n",
            "step:31, loss:3.47971248626709\n",
            "32\n",
            "step:32, loss:3.9884161949157715\n",
            "33\n",
            "step:33, loss:3.452383041381836\n",
            "34\n",
            "step:34, loss:5.278252601623535\n",
            "35\n",
            "step:35, loss:7.841246128082275\n",
            "36\n",
            "step:36, loss:21.864246368408203\n",
            "37\n",
            "step:37, loss:2.8590080738067627\n",
            "38\n",
            "step:38, loss:5.370919704437256\n",
            "39\n",
            "step:39, loss:2.5494027137756348\n",
            "40\n",
            "step:40, loss:3.980170726776123\n",
            "41\n",
            "step:41, loss:71.86272430419922\n",
            "42\n",
            "step:42, loss:3.566070318222046\n",
            "43\n",
            "step:43, loss:4.537895679473877\n",
            "44\n",
            "step:44, loss:17.468725204467773\n",
            "45\n",
            "step:45, loss:6.101861476898193\n",
            "46\n",
            "step:46, loss:9.031688690185547\n",
            "47\n",
            "step:47, loss:4.077576160430908\n",
            "48\n",
            "step:48, loss:8.341736793518066\n",
            "49\n",
            "step:49, loss:10.254719734191895\n",
            "50\n",
            "step:50, loss:34.88569259643555\n",
            "51\n",
            "step:51, loss:6.699459075927734\n",
            "52\n",
            "step:52, loss:12.99478530883789\n",
            "53\n",
            "step:53, loss:17.81381607055664\n",
            "54\n",
            "step:54, loss:5.361053466796875\n",
            "55\n",
            "step:55, loss:10.193582534790039\n",
            "56\n",
            "step:56, loss:4.496430397033691\n",
            "57\n",
            "step:57, loss:7.215559005737305\n",
            "58\n",
            "step:58, loss:2.7478034496307373\n",
            "59\n",
            "step:59, loss:7.030409812927246\n",
            "60\n",
            "step:60, loss:7.097765922546387\n",
            "61\n",
            "step:61, loss:2.6413235664367676\n",
            "62\n",
            "step:62, loss:3.6422321796417236\n",
            "63\n",
            "step:63, loss:4.155130386352539\n",
            "64\n",
            "step:64, loss:3.1729483604431152\n",
            "65\n",
            "step:65, loss:15.76842975616455\n",
            "66\n",
            "step:66, loss:54.571388244628906\n",
            "67\n",
            "step:67, loss:16.567672729492188\n",
            "68\n",
            "step:68, loss:6.477141380310059\n",
            "69\n",
            "step:69, loss:3.65751051902771\n",
            "18\n",
            "-----\n",
            "0\n",
            "step:0, loss:2.515014171600342\n",
            "1\n",
            "step:1, loss:5.556222438812256\n",
            "2\n",
            "step:2, loss:3.6643412113189697\n",
            "3\n",
            "step:3, loss:3.2246389389038086\n",
            "4\n",
            "step:4, loss:16.018348693847656\n",
            "5\n",
            "step:5, loss:68.35558319091797\n",
            "6\n",
            "step:6, loss:5.451582908630371\n",
            "7\n",
            "step:7, loss:5.204051494598389\n",
            "8\n",
            "step:8, loss:2.957024574279785\n",
            "9\n",
            "step:9, loss:4.604331970214844\n",
            "10\n",
            "step:10, loss:18.20051383972168\n",
            "11\n",
            "step:11, loss:4.705354690551758\n",
            "12\n",
            "step:12, loss:46.220760345458984\n",
            "13\n",
            "step:13, loss:6.468108177185059\n",
            "14\n",
            "step:14, loss:6.028316974639893\n",
            "15\n",
            "step:15, loss:5.285223007202148\n",
            "16\n",
            "step:16, loss:3.78663969039917\n",
            "17\n",
            "step:17, loss:11.47964859008789\n",
            "18\n",
            "step:18, loss:1.717847466468811\n",
            "19\n",
            "step:19, loss:2.799838066101074\n",
            "20\n",
            "step:20, loss:4.885293006896973\n",
            "21\n",
            "step:21, loss:5.767125606536865\n",
            "22\n",
            "step:22, loss:4.620670795440674\n",
            "23\n",
            "step:23, loss:35.332244873046875\n",
            "24\n",
            "step:24, loss:2.745795726776123\n",
            "25\n",
            "step:25, loss:18.30181884765625\n",
            "26\n",
            "step:26, loss:14.696634292602539\n",
            "27\n",
            "step:27, loss:6.742918491363525\n",
            "28\n",
            "step:28, loss:45.0129508972168\n",
            "29\n",
            "step:29, loss:1.6360397338867188\n",
            "30\n",
            "step:30, loss:7.389228820800781\n",
            "31\n",
            "step:31, loss:10.811403274536133\n",
            "32\n",
            "step:32, loss:5.541345119476318\n",
            "33\n",
            "step:33, loss:7.070795059204102\n",
            "34\n",
            "step:34, loss:2.357109546661377\n",
            "35\n",
            "step:35, loss:3.8151726722717285\n",
            "36\n",
            "step:36, loss:2.9817376136779785\n",
            "37\n",
            "step:37, loss:46.892425537109375\n",
            "38\n",
            "step:38, loss:6.500665664672852\n",
            "39\n",
            "step:39, loss:1.7629982233047485\n",
            "40\n",
            "step:40, loss:2.942218065261841\n",
            "41\n",
            "step:41, loss:21.511493682861328\n",
            "42\n",
            "step:42, loss:7.157238960266113\n",
            "43\n",
            "step:43, loss:12.842559814453125\n",
            "44\n",
            "step:44, loss:6.340848922729492\n",
            "45\n",
            "step:45, loss:7.375941276550293\n",
            "46\n",
            "step:46, loss:6.544415473937988\n",
            "47\n",
            "step:47, loss:4.753472805023193\n",
            "48\n",
            "step:48, loss:11.224160194396973\n",
            "49\n",
            "step:49, loss:21.634456634521484\n",
            "50\n",
            "step:50, loss:3.6624913215637207\n",
            "51\n",
            "step:51, loss:4.138047218322754\n",
            "52\n",
            "step:52, loss:5.709724426269531\n",
            "53\n",
            "step:53, loss:15.71833610534668\n",
            "54\n",
            "step:54, loss:5.100131034851074\n",
            "55\n",
            "step:55, loss:3.149960517883301\n",
            "56\n",
            "step:56, loss:21.281137466430664\n",
            "57\n",
            "step:57, loss:4.908874034881592\n",
            "58\n",
            "step:58, loss:10.413542747497559\n",
            "59\n",
            "step:59, loss:6.316999435424805\n",
            "60\n",
            "step:60, loss:7.169915199279785\n",
            "61\n",
            "step:61, loss:10.856779098510742\n",
            "62\n",
            "step:62, loss:9.614415168762207\n",
            "63\n",
            "step:63, loss:17.889507293701172\n",
            "64\n",
            "step:64, loss:6.905215740203857\n",
            "65\n",
            "step:65, loss:12.826591491699219\n",
            "66\n",
            "step:66, loss:36.87899398803711\n",
            "67\n",
            "step:67, loss:3.265779495239258\n",
            "68\n",
            "step:68, loss:4.176456451416016\n",
            "69\n",
            "step:69, loss:1.214019536972046\n",
            "19\n",
            "-----\n",
            "0\n",
            "step:0, loss:15.444621086120605\n",
            "1\n",
            "step:1, loss:34.05259704589844\n",
            "2\n",
            "step:2, loss:9.444931030273438\n",
            "3\n",
            "step:3, loss:4.265621185302734\n",
            "4\n",
            "step:4, loss:11.234737396240234\n",
            "5\n",
            "step:5, loss:7.405609607696533\n",
            "6\n",
            "step:6, loss:10.138419151306152\n",
            "7\n",
            "step:7, loss:5.9051923751831055\n",
            "8\n",
            "step:8, loss:2.9551925659179688\n",
            "9\n",
            "step:9, loss:4.258983612060547\n",
            "10\n",
            "step:10, loss:2.1642472743988037\n",
            "11\n",
            "step:11, loss:2.9864416122436523\n",
            "12\n",
            "step:12, loss:2.392101764678955\n",
            "13\n",
            "step:13, loss:12.64218807220459\n",
            "14\n",
            "step:14, loss:4.502623558044434\n",
            "15\n",
            "step:15, loss:34.6767578125\n",
            "16\n",
            "step:16, loss:2.8882298469543457\n",
            "17\n",
            "step:17, loss:18.960853576660156\n",
            "18\n",
            "step:18, loss:12.984210968017578\n",
            "19\n",
            "step:19, loss:10.094779968261719\n",
            "20\n",
            "step:20, loss:4.341760635375977\n",
            "21\n",
            "step:21, loss:5.516773223876953\n",
            "22\n",
            "step:22, loss:2.362964153289795\n",
            "23\n",
            "step:23, loss:5.995682239532471\n",
            "24\n",
            "step:24, loss:24.33104705810547\n",
            "25\n",
            "step:25, loss:13.836265563964844\n",
            "26\n",
            "step:26, loss:6.279128551483154\n",
            "27\n",
            "step:27, loss:2.1393113136291504\n",
            "28\n",
            "step:28, loss:9.182317733764648\n",
            "29\n",
            "step:29, loss:9.252521514892578\n",
            "30\n",
            "step:30, loss:7.058928966522217\n",
            "31\n",
            "step:31, loss:3.3655436038970947\n",
            "32\n",
            "step:32, loss:3.910463809967041\n",
            "33\n",
            "step:33, loss:3.4494571685791016\n",
            "34\n",
            "step:34, loss:1.8734714984893799\n",
            "35\n",
            "step:35, loss:8.38230037689209\n",
            "36\n",
            "step:36, loss:37.95073318481445\n",
            "37\n",
            "step:37, loss:21.366565704345703\n",
            "38\n",
            "step:38, loss:3.040837049484253\n",
            "39\n",
            "step:39, loss:5.662120819091797\n",
            "40\n",
            "step:40, loss:19.45039176940918\n",
            "41\n",
            "step:41, loss:5.751614570617676\n",
            "42\n",
            "step:42, loss:13.982748031616211\n",
            "43\n",
            "step:43, loss:1.4385290145874023\n",
            "44\n",
            "step:44, loss:2.3502933979034424\n",
            "45\n",
            "step:45, loss:12.31683349609375\n",
            "46\n",
            "step:46, loss:2.319424629211426\n",
            "47\n",
            "step:47, loss:5.494690895080566\n",
            "48\n",
            "step:48, loss:2.8733901977539062\n",
            "49\n",
            "step:49, loss:3.7233636379241943\n",
            "50\n",
            "step:50, loss:4.588741302490234\n",
            "51\n",
            "step:51, loss:8.072298049926758\n",
            "52\n",
            "step:52, loss:2.954010486602783\n",
            "53\n",
            "step:53, loss:9.729507446289062\n",
            "54\n",
            "step:54, loss:1.2530782222747803\n",
            "55\n",
            "step:55, loss:36.084930419921875\n",
            "56\n",
            "step:56, loss:11.118363380432129\n",
            "57\n",
            "step:57, loss:2.4101078510284424\n",
            "58\n",
            "step:58, loss:14.971369743347168\n",
            "59\n",
            "step:59, loss:19.36260223388672\n",
            "60\n",
            "step:60, loss:24.99053382873535\n",
            "61\n",
            "step:61, loss:5.701186180114746\n",
            "62\n",
            "step:62, loss:2.833613395690918\n",
            "63\n",
            "step:63, loss:4.216656684875488\n",
            "64\n",
            "step:64, loss:12.933730125427246\n",
            "65\n",
            "step:65, loss:2.739887237548828\n",
            "66\n",
            "step:66, loss:4.8612565994262695\n",
            "67\n",
            "step:67, loss:2.4299893379211426\n",
            "68\n",
            "step:68, loss:95.98533630371094\n",
            "69\n",
            "step:69, loss:4.534036636352539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performance"
      ],
      "metadata": {
        "id": "_w1sXTNkL_Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    output = []\n",
        "    for batch in dataloader:\n",
        "        batch_inputs, batch_masks, _ = \\\n",
        "                                  tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            output += model(batch_inputs, \n",
        "                            batch_masks).view(1,-1).tolist()[0]\n",
        "    return output\n",
        "\n",
        "def r2_score(outputs, labels):\n",
        "    labels_mean = torch.mean(labels)\n",
        "    ss_tot = torch.sum((labels - labels_mean) ** 2)\n",
        "    ss_res = torch.sum((labels - outputs) ** 2)\n",
        "    r2 = 1 - ss_res / ss_tot\n",
        "    return r2"
      ],
      "metadata": {
        "id": "iwuwB9jjMAbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_set = val_data_it[['description', 'demand']]\n",
        "val_set['cleaned_description'] = \\\n",
        "                val_set.description.apply(clean_text)\n",
        "encoded_val_corpus = \\\n",
        "                tokenizer(text=val_set.cleaned_description.tolist(),\n",
        "                          add_special_tokens=True,\n",
        "                          padding='max_length',\n",
        "                          truncation='longest_first',\n",
        "                          max_length=300,\n",
        "                          return_attention_mask=True)\n",
        "val_input_ids = np.array(encoded_val_corpus['input_ids'])\n",
        "val_attention_mask = np.array(encoded_val_corpus['attention_mask'])\n",
        "val_labels = val_set.demand.to_numpy()\n",
        "# val_labels = price_scaler.transform(val_labels.reshape(-1, 1))\n",
        "val_dataloader = create_dataloaders(val_input_ids, \n",
        "                         val_attention_mask, val_labels, batch_size)\n",
        "# y_pred_scaled = predict(model, val_dataloader, device)\n",
        "y_pred = predict(model, val_dataloader, device)\n",
        "y_test = val_set.demand.to_numpy()"
      ],
      "metadata": {
        "id": "9U_lTZJgMDkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# n = data[\"comment_clean\"].str.len()\n",
        "nn, bins, patches = plt.hist(y_pred, 30, facecolor ='g', alpha=0.75)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "yQ1Qq0aKadqj",
        "outputId": "aebf7150-87ee-419e-934a-61ab6bc852ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###mean pisson deviance"
      ],
      "metadata": {
        "id": "VarK-3f2tM6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_poisson_deviance(y_true,y_pred):\n",
        "  prediction=y_pred.copy()\n",
        "  prediction = np.array(prediction)\n",
        "  prediction[np.where(prediction==0)]=10**(-10)\n",
        "  return mean_poisson_deviance(y_true,prediction)\n",
        "from sklearn.metrics import mean_poisson_deviance\n",
        "custom_poisson_deviance(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85D9ev_q2QGN",
        "outputId": "177c8458-4673-47a7-ea2c-d5d157e9aa15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.000836979970725"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test listing prediction"
      ],
      "metadata": {
        "id": "TKvmWUnsshIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    output = []\n",
        "    for batch in dataloader:\n",
        "        batch_inputs, batch_masks = \\\n",
        "                                  tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            output += model(batch_inputs, \n",
        "                            batch_masks).view(1,-1).tolist()[0]\n",
        "    return output\n",
        "\n",
        "def r2_score(outputs, labels):\n",
        "    labels_mean = torch.mean(labels)\n",
        "    ss_tot = torch.sum((labels - labels_mean) ** 2)\n",
        "    ss_res = torch.sum((labels - outputs) ** 2)\n",
        "    r2 = 1 - ss_res / ss_tot\n",
        "    return r2\n",
        "y_pred = predict(model, train_dataloader, device)"
      ],
      "metadata": {
        "id": "2fsS2v8ityy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_it[\"Prediction\"] = y_pred"
      ],
      "metadata": {
        "id": "W6oktjrPscB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fill data"
      ],
      "metadata": {
        "id": "b3u7y1LguiM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(PATH_GDRIVE_TMP + \"/test_overall_data_with_prediction_WN.csv\")\n",
        "# data = pd.read_csv(PATH_GDRIVE_TMP + \"/test_overall_data_with_prediction_NN.csv\")"
      ],
      "metadata": {
        "id": "aamqX5zMuE0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[df_it.index, \"Prediction\"] = df_it[\"Prediction\"]"
      ],
      "metadata": {
        "id": "3qp11mWAu0bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(data, open(PATH_GDRIVE_TMP + \"/test_data_with_prediction_WN.pkl\", \"wb\"))\n",
        "data.to_csv(PATH_GDRIVE_TMP+\"/test_overall_data_with_prediction_WN.csv\", index=False)"
      ],
      "metadata": {
        "id": "_A15kZZh0UAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(data, open(PATH_GDRIVE_TMP + \"/test_overall_data_with_prediction_NN.pkl\", \"wb\"))\n",
        "# data.to_csv(PATH_GDRIVE_TMP+\"/test_overall_data_with_prediction_NN.csv\", index=False)"
      ],
      "metadata": {
        "id": "yex4BgG-EWbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn, bins, patches = plt.hist(data[\"Prediction\"],50, facecolor ='g', alpha=0.75)\n",
        " = data.copy()\n",
        "d1.loc[d1[\"Prediction\"]<0,\"Prediction\"] = 0\n",
        "nn, bins, patches = plt.hist(d1[\"Prediction\"],50, facecolor ='r', alpha=0.75)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "1o0oaUdbbTj6",
        "outputId": "4f5ac3b2-dae1-43e5-81f7-35187a8c7f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQiklEQVR4nO3df8ydZX3H8fdHQLeoCUVqZaVbmesyMZmFNMCif1CNUJhZMVkIZNPGkNQ/IMHoMqv/4DAkXTJxM3MkVRpqojIyZTSmGXasifMPkdZ2/KqEDiG0aWkdqBgTFtx3fzxXs7P2+f2c58d5rvcreXLu+3v/ONeVnn7OfV/nPvdJVSFJ6sMbFrsBkqSFY+hLUkcMfUnqiKEvSR0x9CWpI+cudgMmc+GFF9batWsXuxmSNFIOHDjw06paOd6yJR36a9euZf/+/YvdDEkaKUlemGiZwzuS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRJf2N3KHYuHH8+r59C9sOSVoCPNKXpI4Y+pLUEUNfkjoyZegnWZNkX5KnkzyV5PZW/1ySY0kOtb/rB7b5TJIjSZ5Jcu1AfVOrHUmybX66JEmayHQ+yH0d+FRV/SjJW4EDSfa2ZV+sqr8ZXDnJpcBNwLuB3wL+Ncnvt8VfBj4IHAUeS7K7qp4eRkckSVObMvSr6jhwvE2/muQwsHqSTTYD91fVa8BPkhwBrmjLjlTVcwBJ7m/rGvqStEBmNKafZC1wGfBoK92W5PEkO5OsaLXVwIsDmx1ttYnqZz7H1iT7k+w/derUTJonSZrCtEM/yVuAbwGfqKpfAPcA7wTWM3Ym8IVhNKiqdlTVhqrasHLluL/2JUmapWl9OSvJeYwF/ter6tsAVfXSwPKvAN9ps8eANQObX9xqTFKXJC2A6Vy9E+Be4HBV3T1Qv2hgtQ8DT7bp3cBNSd6U5BJgHfBD4DFgXZJLkryRsQ97dw+nG5Kk6ZjOkf57gY8ATyQ51GqfBW5Osh4o4Hng4wBV9VSSBxj7gPZ14Naq+jVAktuAh4FzgJ1V9dQQ+yJJmsJ0rt75PpBxFu2ZZJu7gLvGqe+ZbDtJ0vzyG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdeTcxW7AfNq4ayN3nzh0Vv2yd6xfhNZI0uLzSF+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI5MGfpJ1iTZl+TpJE8lub3VL0iyN8mz7XFFqyfJl5IcSfJ4kssH9rWlrf9ski3z1y1J0nimc6T/OvCpqroUuAq4NcmlwDbgkapaBzzS5gGuA9a1v63APTD2JgHcAVwJXAHccfqNQpK0MKYM/ao6XlU/atOvAoeB1cBmYFdbbRdwQ5veDHytxvwAOD/JRcC1wN6qermqXgH2ApuG2htJ0qRmNKafZC1wGfAosKqqjrdFJ4BVbXo18OLAZkdbbaL6mc+xNcn+JPtPnTo1k+ZJkqYw7dBP8hbgW8AnquoXg8uqqoAaRoOqakdVbaiqDStXrhzGLiVJzbRCP8l5jAX+16vq2638Uhu2oT2ebPVjwJqBzS9utYnqkqQFMp2rdwLcCxyuqrsHFu0GTl+BswV4aKD+0XYVz1XAz9sw0MPANUlWtA9wr2k1SdICmc6tld8LfAR4Isnp+xR/FtgOPJDkFuAF4Ma2bA9wPXAE+BXwMYCqejnJ54HH2np3VtXLQ+mFJGlapgz9qvo+kAkWf2Cc9Qu4dYJ97QR2zqSBkqTh8Ru5ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyJQ/jL4cHTxxiE/u2nhWfd+WfYvQGklaOB7pS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIlKGfZGeSk0meHKh9LsmxJIfa3/UDyz6T5EiSZ5JcO1Df1GpHkmwbflckSVOZzpH+fcCmcepfrKr17W8PQJJLgZuAd7dt/iHJOUnOAb4MXAdcCtzc1pUkLaApb7hWVd9Lsnaa+9sM3F9VrwE/SXIEuKItO1JVzwEkub+t+/SMWyxJmrW5jOnfluTxNvyzotVWAy8OrHO01SaqnyXJ1iT7k+w/derUHJonSTrTbEP/HuCdwHrgOPCFYTWoqnZU1Yaq2rBy5cph7VaSxCzvp19VL52eTvIV4Dtt9hiwZmDVi1uNSeqSpAUyqyP9JBcNzH4YOH1lz27gpiRvSnIJsA74IfAYsC7JJUneyNiHvbtn32xJ0mxMeaSf5JvA1cCFSY4CdwBXJ1kPFPA88HGAqnoqyQOMfUD7OnBrVf267ec24GHgHGBnVT019N5IkiY1nat3bh6nfO8k698F3DVOfQ+wZ0atkyQNVZe/kQtw9/ZDZxfv2wj7/J1cScuXt2GQpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHZky9JPsTHIyyZMDtQuS7E3ybHtc0epJ8qUkR5I8nuTygW22tPWfTbJlfrojSZrMudNY5z7g74GvDdS2AY9U1fYk29r8p4HrgHXt70rgHuDKJBcAdwAbgAIOJNldVa8MqyPDcPDEIT65a+NZ9X1b9i1CayRp+KY80q+q7wEvn1HeDOxq07uAGwbqX6sxPwDOT3IRcC2wt6pebkG/F9g0jA5IkqZvtmP6q6rqeJs+Aaxq06uBFwfWO9pqE9XPkmRrkv1J9p86dWqWzZMkjWc6wzuTqqpKUsNoTNvfDmAHwIYNG4a23+m6e/uhs4v3bYR9DvFIGn2zPdJ/qQ3b0B5PtvoxYM3Aehe32kR1SdICmm3o7wZOX4GzBXhooP7RdhXPVcDP2zDQw8A1SVa0K32uaTVJ0gKacngnyTeBq4ELkxxl7Cqc7cADSW4BXgBubKvvAa4HjgC/Aj4GUFUvJ/k88Fhb786qOvPDYUnSPJsy9Kvq5gkWfWCcdQu4dYL97AR2zqh1kqSh8hu5ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkTnfZbMH/riKpOXCI31J6oihL0kdcXhnmvxxFUnLgUf6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjribRjm4OCJQ/CuFWfVL3vHem/PIGlJ8khfkjpi6EtSRwx9SeqIoS9JHTH0JakjXr0zD/xNXUlLlUf6ktSROYV+kueTPJHkUJL9rXZBkr1Jnm2PK1o9Sb6U5EiSx5NcPowOSJKmbxjDOxur6qcD89uAR6pqe5Jtbf7TwHXAuvZ3JXBPe1yW/E1dSUvRfAzvbAZ2teldwA0D9a/VmB8A5ye5aB6eX5I0gbmGfgHfTXIgydZWW1VVx9v0CWBVm14NvDiw7dFW+3+SbE2yP8n+U6dOzbF5kqRBcx3eeV9VHUvydmBvkh8PLqyqSlIz2WFV7QB2AGzYsGFG20qSJjenI/2qOtYeTwIPAlcAL50etmmPJ9vqx4A1A5tf3GqSpAUy6yP9JG8G3lBVr7bpa4A7gd3AFmB7e3yobbIbuC3J/Yx9gPvzgWGgLnj9vqTFNpfhnVXAg0lO7+cbVfUvSR4DHkhyC/ACcGNbfw9wPXAE+BXwsTk898jyqh5Ji2nWoV9VzwHvGaf+X8AHxqkXcOtsn2858wxA0kLxNgxLhGcAkhaCt2GQpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHfGSzSXM6/clDZuhv8R5/b6kYTL0R9BEZwDgWYCkyRn6I2rcMwDwLEDSpPwgV5I6YuhLUkcMfUnqiKEvSR0x9CWpI169s8z4hS5JkzH0lyG/0CVpIg7vSFJHDH1J6ojDO504eOIQvGvFuMs+uW39WTU/A5CWJ0NffgYgdcTQ17gmOjO47B3rfTOQRphj+pLUEUNfkjpi6EtSRxzT14w41i+NNkNfQ+GbgTQaDH3Nq8m+HzAe3ySk+WXoa0nxhnHS/DL0teSM92Wxg9vHP1vwzECj7uAEZ8KXHX5lXp5vwUM/ySbg74BzgK9W1faFboOWj5kOH8H4t52ASX5sfgLz9Z9Smk8LGvpJzgG+DHwQOAo8lmR3VT29kO1Q32Ya7hOZ6AhtWBb1LGbj2UNsgGdVy8BCH+lfARypqucAktwPbAYMfekMszmLmXdDas9EZ0kzHuqY4M3p4ImZv7H3cua20KG/GnhxYP4ocOXgCkm2Alvb7C+TPDOXJ7wcLgR+Opd9LEH2aTTYp4kk87v+zF1IsrT+rebW59+ZaMGS+yC3qnYAO4a1vyT7q2rDsPa3FNin0WCfRsdy7dd4Fvo2DMeANQPzF7eaJGkBLHToPwasS3JJkjcCNwG7F7gNktStBR3eqarXk9wGPMzYJZs7q+qpeX7aoQ0VLSH2aTTYp9GxXPt1llTVYrdBkrRAvLWyJHXE0Jekjizb0E+yKckzSY4k2bbY7ZmtJDuTnEzy5EDtgiR7kzzbHpfYN3gml2RNkn1Jnk7yVJLbW31k+5XkN5L8MMl/tD79VatfkuTR9jr8x3YBw0hJck6Sg0m+0+ZHuk9Jnk/yRJJDSfa32si+9mZqWYb+wO0ergMuBW5OcunitmrW7gM2nVHbBjxSVeuAR9r8KHkd+FRVXQpcBdza/n1GuV+vAe+vqvcA64FNSa4C/hr4YlX9HvAKcMsitnG2bgcOD8wvhz5trKr1A9fmj/Jrb0aWZegzcLuHqvpv4PTtHkZOVX0PePmM8mZgV5veBdywoI2ao6o6XlU/atOvMhYoqxnhftWYX7bZ89pfAe8H/qnVR6pPAEkuBv4Y+GqbDyPepwmM7GtvppZr6I93u4fVi9SW+bCqqo636RPAqsVszFwkWQtcBjzKiPerDYMcAk4Ce4H/BH5WVa+3VUbxdfi3wF8C/9Pm38bo96mA7yY50G77AiP+2puJJXcbBs1MVVWSkbzuNslbgG8Bn6iqX2TgXiOj2K+q+jWwPsn5wIPAHyxyk+YkyYeAk1V1IMnVi92eIXpfVR1L8nZgb5IfDy4cxdfeTCzXI/3lfruHl5JcBNAeTy5ye2YsyXmMBf7Xq+rbrTzy/QKoqp8B+4A/As5PcvrgatReh+8F/iTJ84wNkb6fsd/CGOU+UVXH2uNJxt6cr2CZvPamY7mG/nK/3cNuYEub3gI8tIhtmbE2LnwvcLiq7h5YNLL9SrKyHeGT5DcZ+82Iw4yF/5+21UaqT1X1maq6uKrWMvZ/6N+q6s8Y4T4leXOSt56eBq4BnmSEX3sztWy/kZvkesbGI0/f7uGuRW7SrCT5JnA1Y7e0fQm4A/hn4AHgt4EXgBur6swPe5esJO8D/h14gv8bK/4sY+P6I9mvJH/I2AeA5zB2MPVAVd2Z5HcZO0q+ADgI/HlVvbZ4LZ2dNrzzF1X1oVHuU2v7g232XOAbVXVXkrcxoq+9mVq2oS9JOttyHd6RJI3D0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kd+V8z4NQv3OSHdwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}